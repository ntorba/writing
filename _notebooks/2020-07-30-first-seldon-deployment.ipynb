{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch a Seldon Deployment\n",
    "> Get an ML endpoint up and running on your cluster!\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [kubernetes, docker]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro\n",
    "In this post, we will walkthrough the first steps towards launching your own seldon deployment! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch cluster\n",
    "To get started, let's get a cluster up and running. If you followed [part 1]() of this series, you can do so with kind. \n",
    "Below, I create a cluster, create a namespace called seldon-intro, then use `kubens` to make seldon-into my default namespace (so I don't have to include it in every command)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kind create cluster \n",
    "!kubectl create namespace seldon-intro\n",
    "!kubens seldon-intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install seldon-core \n",
    "To install seldon-core on the cluster, use helm. To install helm itself, find directions [here](https://helm.sh/), or use `brew install helm` on mac.\n",
    "\n",
    "Once helm is installed, use it to install seldon-core and seldon-core-operator with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!helm install seldon-core seldon-core-operator \\\n",
    "    --repo https://storage.googleapis.com/seldon-charts \\\n",
    "    --set usageMetrics.enabled=true \\\n",
    "    --set ambassador.enabled=true \\\n",
    "    --namespace seldon-intro "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the install is running correctly, run the following command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get deployments, pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a pod and deployment with `seldon-controller-manager` in the name. This pod and deployment house the seldon-core operator, which is an extensions to to the kubernetes api that allows us to deploy seldon inference graphs later on. We don't need to worry much about these details for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build example\n",
    "I'm taking this example code directly from [seldon-core irisClassifier example](https://github.com/SeldonIO/seldon-core/blob/master/examples/models/sklearn_iris/sklearn_iris.ipynb). \n",
    "This is a classic sklearn example we will be able to get up quick. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: iris_classifier: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir iris_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing iris_classifier/train_iris.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile iris_classifier/train_iris.py\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "OUTPUT_FILE = \"iris_classifier/IrisClassifier.sav\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    clf = LogisticRegression(solver=\"liblinear\", multi_class=\"ovr\")\n",
    "    p = Pipeline([(\"clf\", clf)])\n",
    "    print(\"Training model...\")\n",
    "    p.fit(X, y)\n",
    "    print(\"Model trained!\")\n",
    "\n",
    "    print(f\"Saving model in {OUTPUT_FILE}\")\n",
    "    joblib.dump(p, OUTPUT_FILE)\n",
    "    print(\"Model saved!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading iris data set...\")\n",
    "    iris = datasets.load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    print(\"Dataset loaded!\")\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading iris data set...\n",
      "Dataset loaded!\n",
      "Training model...\n",
      "Model trained!\n",
      "Saving model in IrisClassifier.sav\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "!python iris_classifier/train_iris.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing iris_classifier/IrisClassifier.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile iris_classifier/IrisClassifier.py\n",
    "import joblib\n",
    "\n",
    "class IrisClassifier(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = joblib.load('IrisClassifier.sav')\n",
    "\n",
    "    def predict(self,X,features_names):\n",
    "        return self.model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to slightly differ from their example, and use a Dockerfile to create the docker image for this component instead of s2i. Feel free to use s2i directly from their example instead! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing iris_classifier/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile iris_classifier/requirements.txt\n",
    "sklearn\n",
    "seldon-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting iris_classifier/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile iris_classifier/Dockerfile\n",
    "FROM python:3.7-slim\n",
    "COPY . /app\n",
    "WORKDIR /app\n",
    "RUN pip install -r requirements.txt\n",
    "EXPOSE 5000\n",
    "\n",
    "# Define environment variable\n",
    "ENV MODEL_NAME IrisClassifier \n",
    "ENV API_TYPE REST\n",
    "ENV SERVICE_TYPE MODEL \n",
    "ENV PERSISTENCE 0\n",
    "\n",
    "# seldon-core-microservice is a command line tool installed with the seldon-core python libray. You can use this locally as well!\n",
    "CMD exec seldon-core-microservice $MODEL_NAME $API_TYPE --service-type $SERVICE_TYPE --persistence $PERSISTENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test this example, let's build and run the docker image! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  10.24kB\n",
      "Step 1/10 : FROM python:3.7-slim\n",
      " ---> b386e7420fc3\n",
      "Step 2/10 : COPY . /app\n",
      " ---> 76c42605d763\n",
      "Step 3/10 : WORKDIR /app\n",
      " ---> Running in 85636b5172e2\n",
      "Removing intermediate container 85636b5172e2\n",
      " ---> f4bf613a6752\n",
      "Step 4/10 : RUN pip install -r requirements.txt\n",
      " ---> Running in a899f52db252\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting seldon-core\n",
      "  Downloading seldon_core-1.2.2-py3-none-any.whl (108 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.1-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
      "Collecting gunicorn<20.1.0,>=19.9.0\n",
      "  Downloading gunicorn-20.0.4-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/site-packages (from seldon-core->-r requirements.txt (line 2)) (47.3.1)\n",
      "Collecting jsonschema<4.0.0\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting protobuf<4.0.0\n",
      "  Downloading protobuf-3.12.4-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting grpcio-opentracing<1.2.0,>=1.1.4\n",
      "  Downloading grpcio_opentracing-1.1.4-py3-none-any.whl (14 kB)\n",
      "Collecting Flask-cors<4.0.0\n",
      "  Downloading Flask_Cors-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Collecting minio<6.0.0,>=4.0.9\n",
      "  Downloading minio-5.0.10-py2.py3-none-any.whl (75 kB)\n",
      "Collecting requests<3.0.0\n",
      "  Downloading requests-2.24.0-py2.py3-none-any.whl (61 kB)\n",
      "Collecting Flask<2.0.0\n",
      "  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
      "Collecting redis<4.0.0\n",
      "  Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB)\n",
      "Collecting Flask-OpenTracing<1.2.0,>=1.1.0\n",
      "  Downloading Flask-OpenTracing-1.1.0.tar.gz (8.2 kB)\n",
      "Collecting jaeger-client<4.4.0,>=4.1.0\n",
      "  Downloading jaeger-client-4.3.0.tar.gz (81 kB)\n",
      "Collecting numpy<2.0.0\n",
      "  Downloading numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting prometheus-client<0.9.0,>=0.7.1\n",
      "  Downloading prometheus_client-0.8.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting PyYAML<5.4\n",
      "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
      "Collecting opentracing<2.4.0,>=2.2.0\n",
      "  Downloading opentracing-2.3.0.tar.gz (48 kB)\n",
      "Collecting flatbuffers<2.0.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting grpcio<2.0.0\n",
      "  Downloading grpcio-1.30.0-cp37-cp37m-manylinux2010_x86_64.whl (3.0 MB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting six>=1.11.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-1.7.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting pyrsistent>=0.14.0\n",
      "  Downloading pyrsistent-0.16.0.tar.gz (108 kB)\n",
      "Collecting attrs>=17.4.0\n",
      "  Downloading attrs-19.3.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting configparser\n",
      "  Downloading configparser-5.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting python-dateutil\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting certifi\n",
      "  Downloading certifi-2020.6.20-py2.py3-none-any.whl (156 kB)\n",
      "Collecting urllib3\n",
      "  Downloading urllib3-1.25.10-py2.py3-none-any.whl (127 kB)\n",
      "Collecting pytz\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Werkzeug>=0.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting Jinja2>=2.10.1\n",
      "  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting threadloop<2,>=1\n",
      "  Downloading threadloop-1.0.2.tar.gz (4.9 kB)\n",
      "Collecting thrift\n",
      "  Downloading thrift-0.13.0.tar.gz (59 kB)\n",
      "Collecting tornado>=4.3\n",
      "  Downloading tornado-6.0.4.tar.gz (496 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (27 kB)\n",
      "Building wheels for collected packages: sklearn, Flask-OpenTracing, jaeger-client, PyYAML, opentracing, pyrsistent, threadloop, thrift, tornado\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1315 sha256=d57a3d7fc8fdc05876bf438f26f8cff4722b0a05138d2bed022fee0a4178e0f3\n",
      "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "  Building wheel for Flask-OpenTracing (setup.py): started\n",
      "  Building wheel for Flask-OpenTracing (setup.py): finished with status 'done'\n",
      "  Created wheel for Flask-OpenTracing: filename=Flask_OpenTracing-1.1.0-py3-none-any.whl size=9070 sha256=a9eea2227c6a62575da5bb4ceff30ac5e17aeb30ecd101c439ecf4159c8d5e8d\n",
      "  Stored in directory: /root/.cache/pip/wheels/42/22/cd/ccb93fa68f4a01fb6c10082f97bcb2af9eb8e43565ce38a292\n",
      "  Building wheel for jaeger-client (setup.py): started\n",
      "  Building wheel for jaeger-client (setup.py): finished with status 'done'\n",
      "  Created wheel for jaeger-client: filename=jaeger_client-4.3.0-py3-none-any.whl size=64291 sha256=dc0fbf6075563689924d174359a56b441971377e532fe540aad00cfd50f10dab\n",
      "  Stored in directory: /root/.cache/pip/wheels/4b/b9/d9/efe18893b02a4bc5abb68e0174d4ab10147f7f184dd170758e\n",
      "  Building wheel for PyYAML (setup.py): started\n",
      "  Building wheel for PyYAML (setup.py): finished with status 'done'\n",
      "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44619 sha256=9a28fcdb6b77d49046224761229a1fa1270299f45df01b3b5ae6de0a1daca067\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\n",
      "  Building wheel for opentracing (setup.py): started\n",
      "  Building wheel for opentracing (setup.py): finished with status 'done'\n",
      "  Created wheel for opentracing: filename=opentracing-2.3.0-py3-none-any.whl size=51347 sha256=605e45a582659fe490b17eb5988ee9f92fa214718c7604289f08a50df86acb66\n",
      "  Stored in directory: /root/.cache/pip/wheels/19/c5/4b/b030afc055aa78698cd96eb4b168b7f91bd9254191bf4e9f9f\n",
      "  Building wheel for pyrsistent (setup.py): started\n",
      "  Building wheel for pyrsistent (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrsistent: filename=pyrsistent-0.16.0-cp37-cp37m-linux_x86_64.whl size=56582 sha256=27a2d1e0299e32ba654bd4a8271c2637403c7ef324b44e2cd984215077e5ebeb\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/52/11/f0920f95c23ed7d2d0b05f2b7b2f4509e87a20cfe8ea43d987\n",
      "  Building wheel for threadloop (setup.py): started\n",
      "  Building wheel for threadloop (setup.py): finished with status 'done'\n",
      "  Created wheel for threadloop: filename=threadloop-1.0.2-py3-none-any.whl size=3423 sha256=18cf5f752d27762c81dff6886c477c87643fe81557c07c7a09bf0f019fedcd6c\n",
      "  Stored in directory: /root/.cache/pip/wheels/08/93/e3/037c2555d98964d9ca537dabb39827a2b72470a679b5c0de37\n",
      "  Building wheel for thrift (setup.py): started\n",
      "  Building wheel for thrift (setup.py): finished with status 'done'\n",
      "  Created wheel for thrift: filename=thrift-0.13.0-py3-none-any.whl size=154885 sha256=aaf21a6909c23fd65626437406e9378d6a68462f9a513723fe8ea68260bc6d6c\n",
      "  Stored in directory: /root/.cache/pip/wheels/79/35/5a/19f5dadf91f62bd783aaa8385f700de9bc14772e09ab0f006a\n",
      "  Building wheel for tornado (setup.py): started\n",
      "  Building wheel for tornado (setup.py): finished with status 'done'\n",
      "  Created wheel for tornado: filename=tornado-6.0.4-cp37-cp37m-linux_x86_64.whl size=415150 sha256=48ef74922c2f09c562d7c1e368321240410a5b5cfb847d76cd4a780bab72a33b\n",
      "  Stored in directory: /root/.cache/pip/wheels/7d/14/fa/d88fb5da77d813ea0ffca38a2ab2a052874e9e1142bad0b348\n",
      "Successfully built sklearn Flask-OpenTracing jaeger-client PyYAML opentracing pyrsistent threadloop thrift tornado\n",
      "Installing collected packages: joblib, numpy, scipy, threadpoolctl, scikit-learn, sklearn, gunicorn, six, zipp, importlib-metadata, pyrsistent, attrs, jsonschema, protobuf, opentracing, grpcio, grpcio-opentracing, itsdangerous, Werkzeug, MarkupSafe, Jinja2, click, Flask, Flask-cors, configparser, python-dateutil, certifi, urllib3, pytz, minio, chardet, idna, requests, redis, Flask-OpenTracing, tornado, threadloop, thrift, jaeger-client, prometheus-client, PyYAML, flatbuffers, seldon-core\n",
      "Successfully installed Flask-1.1.2 Flask-OpenTracing-1.1.0 Flask-cors-3.0.8 Jinja2-2.11.2 MarkupSafe-1.1.1 PyYAML-5.3.1 Werkzeug-1.0.1 attrs-19.3.0 certifi-2020.6.20 chardet-3.0.4 click-7.1.2 configparser-5.0.0 flatbuffers-1.12 grpcio-1.30.0 grpcio-opentracing-1.1.4 gunicorn-20.0.4 idna-2.10 importlib-metadata-1.7.0 itsdangerous-1.1.0 jaeger-client-4.3.0 joblib-0.16.0 jsonschema-3.2.0 minio-5.0.10 numpy-1.19.1 opentracing-2.3.0 prometheus-client-0.8.0 protobuf-3.12.4 pyrsistent-0.16.0 python-dateutil-2.8.1 pytz-2020.1 redis-3.5.3 requests-2.24.0 scikit-learn-0.23.1 scipy-1.5.2 seldon-core-1.2.2 six-1.15.0 sklearn-0.0 threadloop-1.0.2 threadpoolctl-2.1.0 thrift-0.13.0 tornado-6.0.4 urllib3-1.25.10 zipp-3.1.0\n",
      "\u001b[91mWARNING: You are using pip version 20.1.1; however, version 20.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container a899f52db252\n",
      " ---> d2f0ae0e17b3\n",
      "Step 5/10 : EXPOSE 5000\n",
      " ---> Running in 16bd0d552e1f\n",
      "Removing intermediate container 16bd0d552e1f\n",
      " ---> 9be0daff411e\n",
      "Step 6/10 : ENV MODEL_NAME IrisClassifier\n",
      " ---> Running in d96157d482bb\n",
      "Removing intermediate container d96157d482bb\n",
      " ---> bdf5abb5c6fa\n",
      "Step 7/10 : ENV API_TYPE REST\n",
      " ---> Running in 0440c0675788\n",
      "Removing intermediate container 0440c0675788\n",
      " ---> 0752c26f1325\n",
      "Step 8/10 : ENV SERVICE_TYPE MODEL\n",
      " ---> Running in e7f4ed43f1e5\n",
      "Removing intermediate container e7f4ed43f1e5\n",
      " ---> cf9d2fb5e410\n",
      "Step 9/10 : ENV PERSISTENCE 0\n",
      " ---> Running in 4eb649daf1b9\n",
      "Removing intermediate container 4eb649daf1b9\n",
      " ---> d2568f29919c\n",
      "Step 10/10 : CMD exec seldon-core-microservice $MODEL_NAME $API_TYPE --service-type $SERVICE_TYPE --persistence $PERSISTENCE\n",
      " ---> Running in e7e96ff83895\n",
      "Removing intermediate container e7e96ff83895\n",
      " ---> 9dbbd5a96d36\n",
      "Successfully built 9dbbd5a96d36\n",
      "Successfully tagged localhost:5000/iris_ex:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build iris_classifier/ -t localhost:5000/iris_ex:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker push localhost:5000/iris_ex:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5eec4505001959617aa301ca764808ba6921abffb450cfcdbed0139e3d74b705\n"
     ]
    }
   ],
   "source": [
    "!docker run --name \"iris_predictor1\" -d --rm -p 5001:5000 localhost:5000/iris_ex:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also remove the -d argument from the above command and run this command in a separate window to see the log output while sending requests to the endpoint. Test the endpoint with the curl below! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\":{\"names\":[\"t:0\",\"t:1\",\"t:2\"],\"ndarray\":[[0.9548873249364059,0.04505474761562512,5.792744796895372e-05]]},\"meta\":{}}\n"
     ]
    }
   ],
   "source": [
    "!curl  -s http://localhost:5001/predict -H \"Content-Type: application/json\" -d '{\"data\":{\"ndarray\":[[5.964,4.006,2.081,1.031]]}}'\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see successful output, you have your first seldon-core-microservice up and running! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
