{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch a Seldon Deployment\n",
    "> Get an ML endpoint up and running on your cluster!\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [kubernetes, docker]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro\n",
    "In this post, we will walkthrough the first steps towards launching your own seldon deployment! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch cluster\n",
    "To get started, let's get a cluster up and running. If you followed [part 1]() of this series, you can do so with kind. \n",
    "Below, I create a cluster, create a namespace called seldon-intro, then use `kubens` to make seldon-into my default namespace (so I don't have to include it in every command)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kind create cluster \n",
    "!kubectl create namespace seldon-intro\n",
    "!kubens seldon-intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install seldon-core \n",
    "To install seldon-core on the cluster, use helm. To install helm itself, find directions [here](https://helm.sh/), or use `brew install helm` on mac.\n",
    "\n",
    "Once helm is installed, use it to install seldon-core and seldon-core-operator with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!helm install seldon-core seldon-core-operator \\\n",
    "    --repo https://storage.googleapis.com/seldon-charts \\\n",
    "    --set usageMetrics.enabled=true \\\n",
    "    --set ambassador.enabled=true \\\n",
    "    --namespace seldon-intro "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the install is running correctly, run the following command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get deployments, pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a pod and deployment with `seldon-controller-manager` in the name. This pod and deployment house the seldon-core operator, which is an extensions to to the kubernetes api that allows us to deploy seldon inference graphs later on. We don't need to worry much about these details for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build example\n",
    "I'm taking this example code directly from [seldon-core irisClassifier example](https://github.com/SeldonIO/seldon-core/blob/master/examples/models/sklearn_iris/sklearn_iris.ipynb). \n",
    "This is a classic sklearn example we will be able to get up quick. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: iris_classifier: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir iris_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing iris_classifier/train_iris.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile iris_classifier/train_iris.py\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "OUTPUT_FILE = \"iris_classifier/IrisClassifier.sav\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    clf = LogisticRegression(solver=\"liblinear\", multi_class=\"ovr\")\n",
    "    p = Pipeline([(\"clf\", clf)])\n",
    "    print(\"Training model...\")\n",
    "    p.fit(X, y)\n",
    "    print(\"Model trained!\")\n",
    "\n",
    "    print(f\"Saving model in {OUTPUT_FILE}\")\n",
    "    joblib.dump(p, OUTPUT_FILE)\n",
    "    print(\"Model saved!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading iris data set...\")\n",
    "    iris = datasets.load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    print(\"Dataset loaded!\")\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading iris data set...\n",
      "Dataset loaded!\n",
      "Training model...\n",
      "Model trained!\n",
      "Saving model in IrisClassifier.sav\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "!python iris_classifier/train_iris.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing iris_classifier/IrisClassifier.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile iris_classifier/IrisClassifier.py\n",
    "import joblib\n",
    "\n",
    "class IrisClassifier(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = joblib.load('IrisClassifier.sav')\n",
    "\n",
    "    def predict(self,X,features_names):\n",
    "        return self.model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to slightly differ from their example, and use a Dockerfile to create the docker image for this component instead of s2i. Feel free to use s2i directly from their example instead! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing iris_classifier/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile iris_classifier/requirements.txt\n",
    "sklearn\n",
    "seldon-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting iris_classifier/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile iris_classifier/Dockerfile\n",
    "FROM python:3.7-slim\n",
    "COPY . /app\n",
    "WORKDIR /app\n",
    "RUN pip install -r requirements.txt\n",
    "EXPOSE 5000\n",
    "\n",
    "# Define environment variable\n",
    "ENV MODEL_NAME IrisClassifier \n",
    "ENV API_TYPE REST\n",
    "ENV SERVICE_TYPE MODEL \n",
    "ENV PERSISTENCE 0\n",
    "\n",
    "# seldon-core-microservice is a command line tool installed with the seldon-core python libray. You can use this locally as well!\n",
    "CMD exec seldon-core-microservice $MODEL_NAME $API_TYPE --service-type $SERVICE_TYPE --persistence $PERSISTENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test this example, let's build and run the docker image! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  7.168kB\n",
      "Step 1/10 : FROM python:3.7-slim\n",
      " ---> b386e7420fc3\n",
      "Step 2/10 : COPY . /app\n",
      " ---> e89dd689e61c\n",
      "Step 3/10 : WORKDIR /app\n",
      " ---> Running in 293fb2fc0432\n",
      "Removing intermediate container 293fb2fc0432\n",
      " ---> 1815d73b62c4\n",
      "Step 4/10 : RUN pip install -r requirements.txt\n",
      " ---> Running in 611c0926cddc\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting seldon-core\n",
      "  Downloading seldon_core-1.2.2-py3-none-any.whl (108 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.1-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
      "Collecting gunicorn<20.1.0,>=19.9.0\n",
      "  Downloading gunicorn-20.0.4-py2.py3-none-any.whl (77 kB)\n",
      "Collecting jaeger-client<4.4.0,>=4.1.0\n",
      "  Downloading jaeger-client-4.3.0.tar.gz (81 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/site-packages (from seldon-core->-r requirements.txt (line 2)) (47.3.1)\n",
      "Collecting numpy<2.0.0\n",
      "  Downloading numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting minio<6.0.0,>=4.0.9\n",
      "  Downloading minio-5.0.10-py2.py3-none-any.whl (75 kB)\n",
      "Collecting prometheus-client<0.9.0,>=0.7.1\n",
      "  Downloading prometheus_client-0.8.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting requests<3.0.0\n",
      "  Downloading requests-2.24.0-py2.py3-none-any.whl (61 kB)\n",
      "Collecting jsonschema<4.0.0\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting Flask<2.0.0\n",
      "  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
      "Collecting redis<4.0.0\n",
      "  Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB)\n",
      "Collecting Flask-cors<4.0.0\n",
      "  Downloading Flask_Cors-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Collecting protobuf<4.0.0\n",
      "  Downloading protobuf-3.12.4-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting opentracing<2.4.0,>=2.2.0\n",
      "  Downloading opentracing-2.3.0.tar.gz (48 kB)\n",
      "Collecting Flask-OpenTracing<1.2.0,>=1.1.0\n",
      "  Downloading Flask-OpenTracing-1.1.0.tar.gz (8.2 kB)\n",
      "Collecting grpcio<2.0.0\n",
      "  Downloading grpcio-1.30.0-cp37-cp37m-manylinux2010_x86_64.whl (3.0 MB)\n",
      "Collecting flatbuffers<2.0.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting PyYAML<5.4\n",
      "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
      "Collecting grpcio-opentracing<1.2.0,>=1.1.4\n",
      "  Downloading grpcio_opentracing-1.1.4-py3-none-any.whl (14 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting threadloop<2,>=1\n",
      "  Downloading threadloop-1.0.2.tar.gz (4.9 kB)\n",
      "Collecting thrift\n",
      "  Downloading thrift-0.13.0.tar.gz (59 kB)\n",
      "Collecting tornado>=4.3\n",
      "  Downloading tornado-6.0.4.tar.gz (496 kB)\n",
      "Collecting certifi\n",
      "  Downloading certifi-2020.6.20-py2.py3-none-any.whl (156 kB)\n",
      "Collecting urllib3\n",
      "  Downloading urllib3-1.25.10-py2.py3-none-any.whl (127 kB)\n",
      "Collecting pytz\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting configparser\n",
      "  Downloading configparser-5.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting python-dateutil\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting attrs>=17.4.0\n",
      "  Downloading attrs-19.3.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting six>=1.11.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting pyrsistent>=0.14.0\n",
      "  Downloading pyrsistent-0.16.0.tar.gz (108 kB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-1.7.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Jinja2>=2.10.1\n",
      "  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting Werkzeug>=0.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (27 kB)\n",
      "Building wheels for collected packages: sklearn, jaeger-client, opentracing, Flask-OpenTracing, PyYAML, threadloop, thrift, tornado, pyrsistent\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1315 sha256=c6663f95549bdd109fa052add555e0c4c160b52c7e008d8fea26d816f4db9053\n",
      "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "  Building wheel for jaeger-client (setup.py): started\n",
      "  Building wheel for jaeger-client (setup.py): finished with status 'done'\n",
      "  Created wheel for jaeger-client: filename=jaeger_client-4.3.0-py3-none-any.whl size=64291 sha256=0f18aca992ee72e11b05c7de433a8b5c5959dbb9240e6c1c7e322ee675959048\n",
      "  Stored in directory: /root/.cache/pip/wheels/4b/b9/d9/efe18893b02a4bc5abb68e0174d4ab10147f7f184dd170758e\n",
      "  Building wheel for opentracing (setup.py): started\n",
      "  Building wheel for opentracing (setup.py): finished with status 'done'\n",
      "  Created wheel for opentracing: filename=opentracing-2.3.0-py3-none-any.whl size=51347 sha256=f04a64db0214646796db1d7e861e1a1d398234fb60d2d807cf518b3a871e893e\n",
      "  Stored in directory: /root/.cache/pip/wheels/19/c5/4b/b030afc055aa78698cd96eb4b168b7f91bd9254191bf4e9f9f\n",
      "  Building wheel for Flask-OpenTracing (setup.py): started\n",
      "  Building wheel for Flask-OpenTracing (setup.py): finished with status 'done'\n",
      "  Created wheel for Flask-OpenTracing: filename=Flask_OpenTracing-1.1.0-py3-none-any.whl size=9070 sha256=8889a367cf5e75a7e4416edead3de69fefe432d42b1d2e19c12eb2212597a34a\n",
      "  Stored in directory: /root/.cache/pip/wheels/42/22/cd/ccb93fa68f4a01fb6c10082f97bcb2af9eb8e43565ce38a292\n",
      "  Building wheel for PyYAML (setup.py): started\n",
      "  Building wheel for PyYAML (setup.py): finished with status 'done'\n",
      "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44619 sha256=8abe3f338d2c78bc974f7c9ae3440f99e6df55ee3b262ee6e663cdb6d8ba714e\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\n",
      "  Building wheel for threadloop (setup.py): started\n",
      "  Building wheel for threadloop (setup.py): finished with status 'done'\n",
      "  Created wheel for threadloop: filename=threadloop-1.0.2-py3-none-any.whl size=3423 sha256=18d6bf81e964b05bdda6d3b13e7216b6142041d2a699394a49fead7d6c0bdf4f\n",
      "  Stored in directory: /root/.cache/pip/wheels/08/93/e3/037c2555d98964d9ca537dabb39827a2b72470a679b5c0de37\n",
      "  Building wheel for thrift (setup.py): started\n",
      "  Building wheel for thrift (setup.py): finished with status 'done'\n",
      "  Created wheel for thrift: filename=thrift-0.13.0-py3-none-any.whl size=154885 sha256=502b079d519542e741efa3ca9dd5d3b5ef4f5b92c49756851c508dcb66a8169a\n",
      "  Stored in directory: /root/.cache/pip/wheels/79/35/5a/19f5dadf91f62bd783aaa8385f700de9bc14772e09ab0f006a\n",
      "  Building wheel for tornado (setup.py): started\n",
      "  Building wheel for tornado (setup.py): finished with status 'done'\n",
      "  Created wheel for tornado: filename=tornado-6.0.4-cp37-cp37m-linux_x86_64.whl size=415150 sha256=6fe87d010077fb2bda88f465f8284d05bb7f2e2d431f1ae47162a13026732ba1\n",
      "  Stored in directory: /root/.cache/pip/wheels/7d/14/fa/d88fb5da77d813ea0ffca38a2ab2a052874e9e1142bad0b348\n",
      "  Building wheel for pyrsistent (setup.py): started\n",
      "  Building wheel for pyrsistent (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrsistent: filename=pyrsistent-0.16.0-cp37-cp37m-linux_x86_64.whl size=56582 sha256=0ac45ee5becbce6f6f04ed951c2c44cb82239326c858ad46b9c50da04106c549\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/52/11/f0920f95c23ed7d2d0b05f2b7b2f4509e87a20cfe8ea43d987\n",
      "Successfully built sklearn jaeger-client opentracing Flask-OpenTracing PyYAML threadloop thrift tornado pyrsistent\n",
      "Installing collected packages: numpy, scipy, joblib, threadpoolctl, scikit-learn, sklearn, gunicorn, tornado, threadloop, six, thrift, opentracing, jaeger-client, certifi, urllib3, pytz, configparser, python-dateutil, minio, prometheus-client, idna, chardet, requests, attrs, pyrsistent, zipp, importlib-metadata, jsonschema, itsdangerous, MarkupSafe, Jinja2, click, Werkzeug, Flask, redis, Flask-cors, protobuf, Flask-OpenTracing, grpcio, flatbuffers, PyYAML, grpcio-opentracing, seldon-core\n",
      "Successfully installed Flask-1.1.2 Flask-OpenTracing-1.1.0 Flask-cors-3.0.8 Jinja2-2.11.2 MarkupSafe-1.1.1 PyYAML-5.3.1 Werkzeug-1.0.1 attrs-19.3.0 certifi-2020.6.20 chardet-3.0.4 click-7.1.2 configparser-5.0.0 flatbuffers-1.12 grpcio-1.30.0 grpcio-opentracing-1.1.4 gunicorn-20.0.4 idna-2.10 importlib-metadata-1.7.0 itsdangerous-1.1.0 jaeger-client-4.3.0 joblib-0.16.0 jsonschema-3.2.0 minio-5.0.10 numpy-1.19.1 opentracing-2.3.0 prometheus-client-0.8.0 protobuf-3.12.4 pyrsistent-0.16.0 python-dateutil-2.8.1 pytz-2020.1 redis-3.5.3 requests-2.24.0 scikit-learn-0.23.1 scipy-1.5.2 seldon-core-1.2.2 six-1.15.0 sklearn-0.0 threadloop-1.0.2 threadpoolctl-2.1.0 thrift-0.13.0 tornado-6.0.4 urllib3-1.25.10 zipp-3.1.0\n",
      "\u001b[91mWARNING: You are using pip version 20.1.1; however, version 20.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container 611c0926cddc\n",
      " ---> e5c9c25eab23\n",
      "Step 5/10 : EXPOSE 5000\n",
      " ---> Running in b1becc35f355\n",
      "Removing intermediate container b1becc35f355\n",
      " ---> 00cd89defe7e\n",
      "Step 6/10 : ENV MODEL_NAME IrisClassifer\n",
      " ---> Running in 62c1a0b246f6\n",
      "Removing intermediate container 62c1a0b246f6\n",
      " ---> 17eeec5d0d61\n",
      "Step 7/10 : ENV API_TYPE REST\n",
      " ---> Running in c03ff1837bd4\n",
      "Removing intermediate container c03ff1837bd4\n",
      " ---> 6aaecc5b27bb\n",
      "Step 8/10 : ENV SERVICE_TYPE MODEL\n",
      " ---> Running in 810e13bc1727\n",
      "Removing intermediate container 810e13bc1727\n",
      " ---> b28972f57a5e\n",
      "Step 9/10 : ENV PERSISTENCE 0\n",
      " ---> Running in 162743c6449e\n",
      "Removing intermediate container 162743c6449e\n",
      " ---> eb4e7d50cab1\n",
      "Step 10/10 : CMD exec seldon-core-microservice $MODEL_NAME $API_TYPE --service-type $SERVICE_TYPE --persistence $PERSISTENCE\n",
      " ---> Running in 2b747f223cad\n",
      "Removing intermediate container 2b747f223cad\n",
      " ---> 04094c475db6\n",
      "Successfully built 04094c475db6\n",
      "Successfully tagged localhost:5000/iris_ex:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build iris_classifier/ -t localhost:5000/iris_ex:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [localhost:5000/iris_ex]\n",
      "\n",
      "\u001b[1Bc29a6535: Preparing \n",
      "\u001b[1Bba1ff41c: Preparing \n",
      "\u001b[1B63f2d025: Preparing \n",
      "\u001b[1Bf01300cf: Preparing \n",
      "\u001b[1Ba0be9040: Preparing \n",
      "\u001b[1B1a837902: Preparing \n",
      "\u001b[7Bc29a6535: Pushed     276MB/269.6MBousingpriceinterface_seldonoutputtransformer_reporter \u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2KPushing  231.5MB/269.6MB\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2Klatest: digest: sha256:218dbbe53e08de366e7e82147853be659f6f5f1c7c807f66c161fdb86fbd0d1c size: 1791\n"
     ]
    }
   ],
   "source": [
    "!docker push localhost:5000/iris_ex:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44e899193312740cd72eab8a23d5dffdafb1f3725682710880dcaca5545b7386\n"
     ]
    }
   ],
   "source": [
    "!docker run --name \"iris_predictor1\" -d --rm -p 5001:5000 localhost:5000/iris_ex:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl  -s http://localhost:5001/predict -H \"Content-Type: application/json\" -d '{\"data\":{\"ndarray\":[[5.964,4.006,2.081,1.031]]}}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see successful output, you have your first seldon-core-microservice up and running! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES\n",
      "e931762bb6d3        registry:2          \"/entrypoint.sh /etc…\"   44 hours ago        Up 44 hours         0.0.0.0:5000->5000/tcp   kind-registry\n"
     ]
    }
   ],
   "source": [
    "!docker container ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
