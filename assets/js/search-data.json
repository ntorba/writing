{
  
    
        "post0": {
            "title": "Title",
            "content": "import json from pykubectl.authenticated_rest import load_kubeconfig from pykubectl.kubectl_client import Pykubectl kc = load_kubeconfig() kc.keys() . dict_keys([&#39;apiVersion&#39;, &#39;clusters&#39;, &#39;contexts&#39;, &#39;current-context&#39;, &#39;kind&#39;, &#39;preferences&#39;, &#39;users&#39;]) . pk = Pykubectl() r = pk.get(&quot;pods&quot;) data = json.loads(r.data) [i[&quot;metadata&quot;][&quot;name&quot;] for i in data[&quot;items&quot;]] . get_url = https://127.0.0.1:32770/api/v1/namespaces/default/pods . [&#39;seldon-92a927e5e90d7602e08ba9b9304f70e8-64b4dd45ff-hvf4c&#39;, &#39;seldon-controller-manager-655fc4ccb6-8x85v&#39;] . r = pk.create(&quot;sklearn_iris_deployment.yaml&quot;) json.loads(r.data) . {&#39;kind&#39;: &#39;Status&#39;, &#39;apiVersion&#39;: &#39;v1&#39;, &#39;metadata&#39;: {}, &#39;status&#39;: &#39;Failure&#39;, &#39;message&#39;: &#39;seldondeployments.machinelearning.seldon.io &#34;seldon-deployment-example&#34; already exists&#39;, &#39;reason&#39;: &#39;AlreadyExists&#39;, &#39;details&#39;: {&#39;name&#39;: &#39;seldon-deployment-example&#39;, &#39;group&#39;: &#39;machinelearning.seldon.io&#39;, &#39;kind&#39;: &#39;seldondeployments&#39;}, &#39;code&#39;: 409} . r = pk.get(&quot;seldondeployments&quot;, resource_name=&quot;seldon-deployment-example&quot;) json.loads(r.data) . get_url = https://127.0.0.1:32770/apis/machinelearning.seldon.io/v1alpha2/namespaces/default/seldondeployments/seldon-deployment-example . {&#39;apiVersion&#39;: &#39;machinelearning.seldon.io/v1alpha2&#39;, &#39;kind&#39;: &#39;SeldonDeployment&#39;, &#39;metadata&#39;: {&#39;creationTimestamp&#39;: &#39;2020-09-11T13:18:55Z&#39;, &#39;generation&#39;: 2, &#39;name&#39;: &#39;seldon-deployment-example&#39;, &#39;namespace&#39;: &#39;default&#39;, &#39;resourceVersion&#39;: &#39;11781&#39;, &#39;selfLink&#39;: &#39;/apis/machinelearning.seldon.io/v1alpha2/namespaces/default/seldondeployments/seldon-deployment-example&#39;, &#39;uid&#39;: &#39;915ec080-ad1d-4c4d-a168-9b94841ffe4c&#39;}, &#39;spec&#39;: {&#39;name&#39;: &#39;sklearn-iris-deployment&#39;, &#39;predictors&#39;: [{&#39;componentSpecs&#39;: [{&#39;metadata&#39;: {&#39;creationTimestamp&#39;: None}, &#39;spec&#39;: {&#39;containers&#39;: [{&#39;image&#39;: &#39;seldonio/sklearn-iris:0.1&#39;, &#39;imagePullPolicy&#39;: &#39;IfNotPresent&#39;, &#39;name&#39;: &#39;sklearn-iris-classifier&#39;, &#39;ports&#39;: [{&#39;containerPort&#39;: 6000, &#39;name&#39;: &#39;metrics&#39;, &#39;protocol&#39;: &#39;TCP&#39;}], &#39;resources&#39;: {}, &#39;volumeMounts&#39;: [{&#39;mountPath&#39;: &#39;/etc/podinfo&#39;, &#39;name&#39;: &#39;seldon-podinfo&#39;}]}]}}], &#39;engineResources&#39;: {}, &#39;graph&#39;: {&#39;endpoint&#39;: {&#39;service_host&#39;: &#39;localhost&#39;, &#39;service_port&#39;: 9000, &#39;type&#39;: &#39;REST&#39;}, &#39;implementation&#39;: &#39;UNKNOWN_IMPLEMENTATION&#39;, &#39;name&#39;: &#39;sklearn-iris-classifier&#39;, &#39;type&#39;: &#39;MODEL&#39;}, &#39;labels&#39;: {&#39;version&#39;: &#39;sklearn-iris-predictor&#39;}, &#39;name&#39;: &#39;sklearn-iris-predictor&#39;, &#39;replicas&#39;: 2, &#39;svcOrchSpec&#39;: {}}]}, &#39;status&#39;: {&#39;address&#39;: {&#39;url&#39;: &#39;http://seldon-deployment-example-sklearn-iris-predictor.default.svc.cluster.local:8000/api/v1.0/predictions&#39;}, &#39;deploymentStatus&#39;: {&#39;seldon-92a927e5e90d7602e08ba9b9304f70e8&#39;: {&#39;availableReplicas&#39;: 1, &#39;replicas&#39;: 2}}, &#39;replicas&#39;: 2, &#39;serviceStatus&#39;: {&#39;seldon-d0934233541ef6b732c88680f8a0e94f&#39;: {&#39;httpEndpoint&#39;: &#39;seldon-d0934233541ef6b732c88680f8a0e94f.default:9000&#39;, &#39;svcName&#39;: &#39;seldon-d0934233541ef6b732c88680f8a0e94f&#39;}, &#39;seldon-deployment-example-sklearn-iris-predictor&#39;: {&#39;grpcEndpoint&#39;: &#39;seldon-deployment-example-sklearn-iris-predictor.default:5001&#39;, &#39;httpEndpoint&#39;: &#39;seldon-deployment-example-sklearn-iris-predictor.default:8000&#39;, &#39;svcName&#39;: &#39;seldon-deployment-example-sklearn-iris-predictor&#39;}}, &#39;state&#39;: &#39;Creating&#39;}} . r = pk.update(&quot;sklearn_iris_deployment.yaml&quot;) json.loads(r.data).keys() . https://127.0.0.1:32770/apis/machinelearning.seldon.io/v1alpha2/namespaces/default/seldondeployments/seldon-deployment-example . dict_keys([&#39;apiVersion&#39;, &#39;kind&#39;, &#39;metadata&#39;, &#39;spec&#39;, &#39;status&#39;]) .",
            "url": "http://drafts.nicktorba.com/2020/09/13/pykubectl_with_library.html",
            "relUrl": "/2020/09/13/pykubectl_with_library.html",
            "date": " • Sep 13, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Multi-component Inference Graph",
            "content": "Reqs . access to kubernetes cluster If you are coming from Launch a local kubernetes cluster or First Seldon Deployment you are ready to follow this example | . | . Goal . Launch a multi-component seldon inference graph on kubernetes builds on concepts shown in First Seldon Deployment | . | . Steps . Define multiple seldon components | Define seldon deployment yaml with multiple components | kubectl apply new inference graph |",
            "url": "http://drafts.nicktorba.com/kubernetes/docker/2020/09/13/bigger-inference-graph.html",
            "relUrl": "/kubernetes/docker/2020/09/13/bigger-inference-graph.html",
            "date": " • Sep 13, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Title",
            "content": "I am very close to understanding this authentication The class FileOrData class is the key. This is actually creating the cert files from the info in the kubeconfig file. Walk through this class to see how it is creating the files to then copy that and see if I can create my own pool_manager . from kubernetes import client, config config.load_kube_config() client.api_client c = client.CoreV1Api() . . import base64 import atexit import tempfile _temp_files = {} def _create_temp_file_with_content(content): if len(_temp_files) == 0: atexit.register(_cleanup_temp_files) # Because we may change context several times, try to remember files we # created and reuse them at a small memory cost. content_key = str(content) if content_key in _temp_files: return _temp_files[content_key] _, name = tempfile.mkstemp() _temp_files[content_key] = name with open(name, &quot;wb&quot;) as fd: fd.write(content.encode() if isinstance(content, str) else content) return name def _cleanup_temp_files(): global _temp_files for temp_file in _temp_files.values(): try: os.remove(temp_file) except OSError: pass _temp_files = {} class FileOrData(object): &quot;&quot;&quot;Utility class to read content of obj[%data_key_name] or file&#39;s content of obj[%file_key_name] and represent it as file or data. Note that the data is preferred. The obj[%file_key_name] will be used iff obj[&#39;%data_key_name&#39;] is not set or empty. Assumption is file content is raw data and data field is base64 string. The assumption can be changed with base64_file_content flag. If set to False, the content of the file will assumed to be base64 and read as is. The default True value will result in base64 encode of the file content after read.&quot;&quot;&quot; def __init__( self, obj, file_key_name, data_key_name=None, file_base_path=&quot;&quot;, base64_file_content=True, ): if not data_key_name: data_key_name = file_key_name + &quot;-data&quot; self._file = None self._data = None self._base64_file_content = base64_file_content if data_key_name in obj: self._data = obj[data_key_name] elif file_key_name in obj: self._file = os.path.normpath( os.path.join(file_base_path, obj[file_key_name]) ) def as_file(self): &quot;&quot;&quot;If obj[%data_key_name] exists, return name of a file with base64 decoded obj[%data_key_name] content otherwise obj[%file_key_name].&quot;&quot;&quot; use_data_if_no_file = not self._file and self._data if use_data_if_no_file: if self._base64_file_content: if isinstance(self._data, str): content = self._data.encode() else: content = self._data self._file = _create_temp_file_with_content( base64.standard_b64decode(content) ) else: self._file = _create_temp_file_with_content(self._data) if self._file and not os.path.isfile(self._file): raise ConfigException(&quot;File does not exists: %s&quot; % self._file) return self._file def as_data(self): &quot;&quot;&quot;If obj[%data_key_name] exists, Return obj[%data_key_name] otherwise base64 encoded string of obj[%file_key_name] file content.&quot;&quot;&quot; use_file_if_no_data = not self._data and self._file if use_file_if_no_data: with open(self._file) as f: if self._base64_file_content: self._data = bytes.decode( base64.standard_b64encode(str.encode(f.read())) ) else: self._data = f.read() return self._data . import os import yaml def get_current(config, current_context): for i_cluster, i_user in zip(config[&quot;clusters&quot;], config[&quot;users&quot;]): if i_cluster[&quot;name&quot;] == current_context: cluster = i_cluster user = i_user name = cluster[&quot;name&quot;] combined = {&quot;name&quot;: name} for k, v in cluster[&quot;cluster&quot;].items(): combined[k] = v for k, v in user[&quot;user&quot;].items(): combined[k] = v return combined else: raise Exception(&quot;No match!&quot;) base_path = os.environ[&quot;KUBECONFIG&quot;] with open(base_path) as f: kubeconfig = yaml.safe_load(f) kubeconfig.keys() c_obj = get_current(kubeconfig, kubeconfig[&quot;current-context&quot;]) c_obj.keys() . import os ssl_ca_cert = FileOrData(c_obj, &quot;certificate-authority&quot;, file_base_path=base_path).as_file() . cert_file = FileOrData( c_obj, &quot;client-certificate&quot;, file_base_path=base_path ).as_file() key_file = FileOrData( c_obj, &quot;client-key&quot;, file_base_path=base_path ).as_file() . print(type(ssl)) . import urllib3 import ssl pool_manager = urllib3.PoolManager( num_pools=4, maxsize=50, cert_reqs=ssl.CERT_REQUIRED, ca_certs=ssl_ca_cert, cert_file=cert_file, key_file=key_file ) . url . url = c_obj[&quot;server&quot;] + &quot;/api/&quot; headers = {&#39;Accept&#39;: &#39;application/json&#39;, &#39;User-Agent&#39;: &#39;OpenAPI-Generator/12.0.0-snapshot/python&#39;, &#39;Content-Type&#39;: &#39;application/json&#39;} r = pool_manager.request( &quot;GET&quot;, url, headers=headers, preload_content=True ) r . import json d = json.loads(r.data) d . dir(r) .",
            "url": "http://drafts.nicktorba.com/2020/09/13/Untitled.html",
            "relUrl": "/2020/09/13/Untitled.html",
            "date": " • Sep 13, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Title",
            "content": "import json from authenticated_rest import get_pool_manager pool_manager, cluster_info = get_pool_manager() url = cluster_info[&quot;server&quot;] + &quot;/apis/&quot; headers = {&#39;Accept&#39;: &#39;application/json&#39;, &#39;User-Agent&#39;: &#39;OpenAPI-Generator/12.0.0-snapshot/python&#39;, &#39;Content-Type&#39;: &#39;application/json&#39;} r = pool_manager.request( &quot;GET&quot;, url, headers=headers, preload_content=True ) print(r.status) # json.loads(r.data) . 200 . !kubectx . arn:aws:eks:us-east-1:792852952478:cluster/amp-provider-nasa-dev1 arn:aws:eks:us-west-2:600765618583:cluster/mlp-eks-dev-cluster-03 docker-desktop docker-for-desktop kind-kind . import yaml import json class Kubectl: def __init__(self): self.pool_manager, self.cluster_info = get_pool_manager() self.base_url = self.cluster_info[&quot;server&quot;] + &quot;/apis&quot; def get(self, plural, api, namespace=&quot;default&quot;): get_url = self.base_url + f&quot;/{api}&quot; + &quot;/namespaces&quot; + f&quot;/{namespace}&quot; + f&quot;/{plural}&quot; print(&quot;get_url = &quot;, get_url) r = pool_manager.request( &quot;GET&quot;, get_url, preload_content=True ) return r def create(self, fpath, namespace=&quot;default&quot;, plural=None): &quot;&quot;&quot; args: resource_name: If you are doing an update, you need to add the name of the actualy deployment to the end of the url &quot;&quot;&quot; with open(fpath) as f: deployment = yaml.safe_load(f) if not plural: plural = deployment[&quot;kind&quot;].lower() + &quot;s&quot; url = self.base_url + f&quot;/{deployment[&#39;apiVersion&#39;]}&quot; + &quot;/namespaces&quot; + f&quot;/{namespace}&quot; + f&quot;/{plural}&quot; r = pool_manager.request( &quot;POST&quot;, url, body=json.dumps(request_body), preload_content=True ) return r def update(self, fpath, namespace=&quot;default&quot;, plural=None, resource_name=None): &quot;&quot;&quot; args: resource_name: If you are doing an update, you need to add the name of the actualy deployment to the end of the url &quot;&quot;&quot; with open(fpath) as f: deployment = yaml.safe_load(f) if not plural: plural = deployment[&quot;kind&quot;].lower() + &quot;s&quot; url = self.base_url + f&quot;/{deployment[&#39;apiVersion&#39;]}&quot; + &quot;/namespaces&quot; + f&quot;/{namespace}&quot; + f&quot;/{plural}&quot; if resource_name: url = url + f&quot;/{resource_name}&quot; print(url) request_body = json.dumps(deployment) print(type(request_body)) r = pool_manager.request( &quot;PATCH&quot;, url, body=request_body, preload_content=True, headers={&#39;Accept&#39;: &#39;application/json&#39;, &#39;Content-Type&#39;: &#39;application/merge-patch+json&#39;, &#39;User-Agent&#39;: &#39;OpenAPI-Generator/12.0.0-snapshot/python&#39;} ) return r kubectl = Kubectl() update_sdep_r = kubectl.update(&quot;/Users/ntorba605/ntorba605/amp/cd/vsgdummy.json&quot;, resource_name=&quot;vsgdummy-002&quot;) print(update_sdep_r.status) list_sdeps_r = kubectl.get(&quot;seldondeployments&quot;, &quot;machinelearning.seldon.io/v1alpha2&quot;) print(list_sdeps_r.status) pods = kubectl.get(&quot;pods&quot;, &quot;apps/v1&quot;) print(pods.status) . https://127.0.0.1:32768/apis/machinelearning.seldon.io/v1alpha2/namespaces/default/seldondeployments/vsgdummy-002 &lt;class &#39;str&#39;&gt; 200 get_url = https://127.0.0.1:32768/apis/machinelearning.seldon.io/v1alpha2/namespaces/default/seldondeployments 200 get_url = https://127.0.0.1:32768/apis/apps/v1/namespaces/default/pods 404 . &#39;https://127.0.0.1:32768/apis/machinelearning.seldon.io/v1alpha2/namespaces/default/seldondeployments/vsgdummy-002&#39; == &quot;https://127.0.0.1:32768/apis/machinelearning.seldon.io/v1alpha2/namespaces/default/seldondeployments/vsgdummy-002&quot; . True . json.loads(update_sdep_r.data).keys() . dict_keys([&#39;apiVersion&#39;, &#39;kind&#39;, &#39;metadata&#39;, &#39;spec&#39;, &#39;status&#39;]) . json.loads(list_sdeps_r.data).keys() . dict_keys([&#39;apiVersion&#39;, &#39;items&#39;, &#39;kind&#39;, &#39;metadata&#39;]) .",
            "url": "http://drafts.nicktorba.com/2020/09/13/PyKubectl_auth.html",
            "relUrl": "/2020/09/13/PyKubectl_auth.html",
            "date": " • Sep 13, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Building a Python Kubernetes Client",
            "content": "Why bother . I don&#39;t like the current official kubernetes python client. When using it, I get frustrated that it doesn&#39;t feel much more like kubectl. I thought it should look something like this: . from pykubectl import Kubectl kubectl = Kubectl() kubectl.apply(&quot;path/to/file.json or yaml&quot;) . but instead it looks like this: . import yaml from kubernetes import client, config config.load_kube_config() with open(path.join(path.dirname(__file__), &quot;nginx-deployment.yaml&quot;)) as f: dep = yaml.safe_load(f) k8s_apps_v1 = client.AppsV1Api() resp = k8s_apps_v1.create_namespaced_deployment( body=dep, namespace=&quot;default&quot;) print(&quot;Deployment created. status=&#39;%s&#39;&quot; % resp.metadata.name) . And if I wanted to create a custom resource intead, I can&#39;t edit the deployment file. I would need to create an entirely new client object. This is fine, but when you use kubectl, you don&#39;t have to do that much extra work. Why is it built like this? I figured the best way to figure this out is to try to build my own client and see what led to this current client. . Brainstorm . What I know so far . Kubernetes recieves commands entirely based on the kubernetes rest api all commands, internal and external, are handled through this api | kubectl works by creating appropriate rest requests for each command | . | kubectl apply -f fpath with only a file supplied as an argument, and it&#39;s great. even for custom resource deployments like seldon or ambassador, all you need to do is supply the file and kubectl figures the rest out for you.. why doesn&#39;t python client copy that pattern? | kubectl is also written in go (which I don&#39;t know) and looks pretty complex, so there&#39;s that | . | The KUBECONFIG environment var tells me how to connect to the cluster the kubeconfig file has a certificate-authority-data field for the cluster, along with a key and other value for each user, but I&#39;m unsure how those are useful | . | Kubernetes auth is hard. I&#39;m not sure how kubectl connects to the cluster | Process . I have the current kubernes client cloned so I can add breakpoints and step through current examples. I did this to see what their api requests look like. I also had the kubectl-proxy running on my local host I used this process to investigate their post request for doing something like listing running pods on the cluster. First, to get the cluster server url, I build a little func to get info from the kubeconfig. Then, I just tried to hit the url with a GET request, like this example: GET /api/v1/namespaces/test/pods I was running this on a kind cluster, so I thought the auth might be a little more relaxed. | . | import os import yaml def get_current(cluster_list, context): for i in cluster_list: if i[&quot;name&quot;] == context: return i else: raise Exception(&quot;No match!&quot;) def get_cluster(): kubeconfig = os.environ[&quot;KUBECONFIG&quot;] kubeconfig with open(kubeconfig) as f: config = yaml.safe_load(f) config.keys() cluster = get_current(config[&quot;clusters&quot;], config[&quot;current-context&quot;]) return cluster cluster = get_cluster() get_pods_path = &quot;/api/v1/namespaces/default/pods&quot; url = cluster[&quot;cluster&quot;][&quot;server&quot;] + &quot;/api&quot; import requests headers = {&#39;Accept&#39;: &#39;application/json&#39;, &#39;User-Agent&#39;: cluster[&quot;name&quot;]} #, &#39;authorization&#39;: f&#39;Bearer {token}&#39;, &#39;Content-Type&#39;: &#39;application/json&#39;} # headers = {&#39;Accept&#39;: &#39;application/json&#39;, &#39;User-Agent&#39;: &#39;OpenAPI-Generator/12.0.0-snapshot/python&#39;, &#39;authorization&#39;: f&#39;Bearer {content}&#39;, &#39;Content-Type&#39;: &#39;application/json&#39;} r = requests.get(url, headers=headers, verify=False) print(r.text) . {&#34;kind&#34;:&#34;Status&#34;,&#34;apiVersion&#34;:&#34;v1&#34;,&#34;metadata&#34;:{},&#34;status&#34;:&#34;Failure&#34;,&#34;message&#34;:&#34;forbidden: User &#34;system:anonymous &#34; cannot get path &#34;/api &#34;&#34;,&#34;reason&#34;:&#34;Forbidden&#34;,&#34;details&#34;:{},&#34;code&#34;:403} . /Users/ntorba605/opt/anaconda3/envs/amp1/lib/python3.7/site-packages/urllib3/connectionpool.py:988: InsecureRequestWarning: Unverified HTTPS request is being made to host &#39;127.0.0.1&#39;. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings InsecureRequestWarning, . Even with the verify=False arg, it is clear that kubernetes is smart enough to not let us get info about it. Clearly, even when running a local cluster, you need more advanced auth to be able to request info from your cluster. Looking further into the python request docs, we see that although we can set verify=False on the client-side, kubernetes rejects our request because the cluster doesn&#39;t care whether or not we verify it.. it needs to be able to verify us. The info to do that must be available in the kubeconfig file, otherwise kubectl wouldn&#39;t be able to run commands on the cluster. However, looking furhter into the requests and doing a fair amount of googling, I couldn&#39;t find any examples of people using the requests library to launch commands on kubernetes. . So, I looked into the current python client to see how they did it. . Doing auth is way fucking harder than I expected it to be. 2 hours in... still haven&#39;t figured out how to do the SSL auth... I fucking hate programming . | So I came across this page: https://kubernetes.io/docs/tasks/administer-cluster/access-cluster-api/, which has commands that are also used in this video: https://www.youtube.com/watch?v=dAUJ3TBwDWo . What I found is how to actually grab the token that we need from the server to make requests, but this still really bothers me because I need to use kubectl to get his token... which means that kubectl is doing some other kind of authentication... | . | I found the magic sauce. It is the FileOrData class from GitHub/python/kubernetes/config/kube_config.py. This class is used to create the ssl_ca_cert, cert_file, and key_file to create a custom urllib3.PoolManager, which is what the kubernetes-client is doing behind the scenes . The urllib3.PoolManager is the preferred option when you need custom auth to make authenticated requests | Using this code allows me to bypass getting the token from the kubectl command, but I need to actually understand what this code is doing... | . | I created the get_current function to very simple mimic the KubeConfigNode class to pass to class DataOrFile, and I adjusted the DataOrFile class to be be used with my simple dictionary . This class is used to create a security bundle to instantiate an authenticated PoolManager (this is done in authenticated_rest.py) | I figured this out by stepping through the kubernetes python client code over and over again to see what was being passed to those functions, which is the information that is in the kubeconfig for user and for the cluster I am a user on the cluster, which is what the client-certificate and client-key are used for (they are in the user section of the kubeconfig | urllib3 docs on this bundle here: https://urllib3.readthedocs.io/en/latest/advanced-usage.html, under the Client Certificates section | . | . | import os import yaml kubeconfig = os.environ[&quot;KUBECONFIG&quot;] kubeconfig with open(kubeconfig) as f: config = yaml.safe_load(f) config.keys() . config[&quot;current-context&quot;] . def get_current(cluster_list, context): for i in cluster_list: if i[&quot;name&quot;] == context: return i else: raise Exception(&quot;No match!&quot;) cluster = get_current(config[&quot;clusters&quot;], config[&quot;current-context&quot;]) cluster . import certifi . import urllib3 import ssl import certifi # pool_manager = urllib3.PoolManager( # num_pools=4, # maxsize=4, # cert_reqs=ssl.CERT_REQUIRED, # ca_certs=certifi.where(), # cert_file=None, # key_file=None, # ) . import base64 TOKEN = &quot;k8s-aws-v1.aHR0cHM6Ly9zdHMudXMtZWFzdC0xLmFtYXpvbmF3cy5jb20vP0FjdGlvbj1HZXRDYWxsZXJJZGVudGl0eSZWZXJzaW9uPTIwMTEtMDYtMTUmWC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BU0lBM1JHTlg2V1BEWkhaRFhOQiUyRjIwMjAwOTAzJTJGdXMtZWFzdC0xJTJGc3RzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyMDA5MDNUMTM1ODE3WiZYLUFtei1FeHBpcmVzPTYwJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCUzQngtazhzLWF3cy1pZCZYLUFtei1TZWN1cml0eS1Ub2tlbj1Gd29HWlhJdllYZHpFTCUyRiUyRiUyRiUyRiUyRiUyRiUyRiUyRiUyRiUyRiUyRndFYURPTWRiNzM1NFBCMmlmRjVraUxuQWY4Q3dUaUY4NWQwUkV6ZyUyQk4lMkZodm90TmVJd0pBSFRsNDRVSlIzd2UlMkZEaGNHWmw5QTFOSTBOR01tM2E1YSUyQldjRURjbWVVWldSYlElMkYyNkJhcDJnNk9oNHZLMmVuajQ1YlB6d2ZBT2N2SGpPVGRvdnhZdFVLQ0U2RGZPJTJGM29YU3NxJTJCZG1tY3I0d0NFR09tajB1dTFIWnNCRSUyRmclMkZkJTJGRmg1eUk1SjUzJTJCdFUybHpyVE1uSERUdlFmNTY4VlZtWlhuZVcxN2YxbVc4UWYlMkZsdlhWVTNhJTJCdGpSbUsyUzJjdk5oVWJEclBmckclMkZmU3kxeUZ2eHQxY2wwcmZiaHJ3ZzU0RHdLNGZpSTEyRTRpb0puMGhuc3hMU2FsaWYlMkJVVFJQRFFXJTJCWVZEQWFQUEV2JTJGTHpLM1pMUU1neXlpRDJjUDZCVEl5UmI2bTNYVDVLMEJZSkVSQjZzZXR3T2s5UDBMYVBrc09LOGcxc0Jrbm1MTjJRSjVxYmo4Y2tkTjVUJTJGM0Q5eUVFMWNvJTNEJlgtQW16LVNpZ25hdHVyZT1iOTZhNGVhYWM0OGViYjc0NmRjMzk5NDI3NTU2NDg1NGExMzg0NmQ0MDM2ZmYzNTJmZjI1ZDExNGVjM2IzMzBl&quot; content = TOKEN.encode() content = base64.standard_b64decode(content) content . ## THIS LINE GRABS THE TOKEN I NEED FOR THE HEADER TO GET AUTHENTICATED!!! !kubectl get secrets -o jsonpath=&quot;{.items[?(@.metadata.annotations[&#39;kubernetes .io/service-account .name&#39;]==&#39;default&#39;)].data.token}&quot;|base64 --decode . get_pods_path = &quot;/api/v1/namespaces/default/pods&quot; url = cluster[&quot;cluster&quot;][&quot;server&quot;] + &quot;/api&quot; import requests token = &quot;eyJhbGciOiJSUzI1NiIsImtpZCI6Im1vNXpWUWxvdnA1cGF3MW1uTU05dldBX1BMYnJKMjBNSXl5bEhhemtvRlUifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJkZWZhdWx0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6ImRlZmF1bHQtdG9rZW4tcDk5Z3YiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGVmYXVsdCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjJmYmUzOTJkLTk4OWQtNDcyMC1hODkxLTJkMzVmYjk2ZTRiMiIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDpkZWZhdWx0OmRlZmF1bHQifQ.NiWZlkUqDj6RQTyONA4d8KfU2qoNpaGwYqeWIrIeGcrBF3uIAa8Op-g26CxPYJ_NIf8ETeId4DJi7pBEM61vyCzes3HI3Xk0IxrOdc9-qbYxr8jcwdCZYqYKg1X9Su8XdnqQI7UTdxIYCJ-EHHtM5nnwilxYOyep6MZClDu02sW__eVIOG0z4H1p2JbEsG2--WiH2W_c7pt-nmQwAubQuN-R2DELR6XMej7o50eU6HoE7SI-A5YgnaC4quTJSZZOze6ziSiUo8olq6nF47wak9d0A898j5JaeCyHbQeFyd3XD4KJl1ZbsBW4jFSRsZAs3kckU0qTKsZY7KKhBGwWoA&quot; headers = {&#39;Accept&#39;: &#39;application/json&#39;, &#39;User-Agent&#39;: cluster[&quot;name&quot;], &#39;authorization&#39;: f&#39;Bearer {token}&#39;, &#39;Content-Type&#39;: &#39;application/json&#39;} # headers = {&#39;Accept&#39;: &#39;application/json&#39;, &#39;User-Agent&#39;: &#39;OpenAPI-Generator/12.0.0-snapshot/python&#39;, &#39;authorization&#39;: f&#39;Bearer {content}&#39;, &#39;Content-Type&#39;: &#39;application/json&#39;} r = requests.get(url, headers=headers, verify=False) # help(requests.get) r.text . from kubernetes import client, config config.load_kube_config() client.api_client c = client.CoreV1Api() headers = {&#39;Accept&#39;: &#39;application/json&#39;, &#39;User-Agent&#39;: &#39;OpenAPI-Generator/12.0.0-snapshot/python&#39;, &#39;authorization&#39;: &#39;Bearer k8s-aws-v1.aHR0cHM6Ly9zdHMudXMtZWFzdC0xLmFtYXpvbmF3cy5jb20vP0FjdGlvbj1HZXRDYWxsZXJJZGVudGl0eSZWZXJzaW9uPTIwMTEtMDYtMTUmWC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BU0lBM1JHTlg2V1BEWkhaRFhOQiUyRjIwMjAwOTAzJTJGdXMtZWFzdC0xJTJGc3RzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyMDA5MDNUMTUyMTU5WiZYLUFtei1FeHBpcmVzPTYwJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCUzQngtazhzLWF3cy1pZCZYLUFtei1TZWN1cml0eS1Ub2tlbj1Gd29HWlhJdllYZHpFTCUyRiUyRiUyRiUyRiUyRiUyRiUyRiUyRiUyRiUyRiUyRndFYURPTWRiNzM1NFBCMmlmRjVraUxuQWY4Q3dUaUY4NWQwUkV6ZyUyQk4lMkZodm90TmVJd0pBSFRsNDRVSlIzd2UlMkZEaGNHWmw5QTFOSTBOR01tM2E1YSUyQldjRURjbWVVWldSYlElMkYyNkJhcDJnNk9oNHZLMmVuajQ1YlB6d2ZBT2N2SGpPVGRvdnhZdFVLQ0U2RGZPJTJGM29YU3NxJTJCZG1tY3I0d0NFR09tajB1dTFIWnNCRSUyRmclMkZkJTJGRmg1eUk1SjUzJTJCdFUybHpyVE1uSERUdlFmNTY4VlZtWlhuZVcxN2YxbVc4UWYlMkZsdlhWVTNhJTJCdGpSbUsyUzJjdk5oVWJEclBmckclMkZmU3kxeUZ2eHQxY2wwcmZiaHJ3ZzU0RHdLNGZpSTEyRTRpb0puMGhuc3hMU2FsaWYlMkJVVFJQRFFXJTJCWVZEQWFQUEV2JTJGTHpLM1pMUU1neXlpRDJjUDZCVEl5UmI2bTNYVDVLMEJZSkVSQjZzZXR3T2s5UDBMYVBrc09LOGcxc0Jrbm1MTjJRSjVxYmo4Y2tkTjVUJTJGM0Q5eUVFMWNvJTNEJlgtQW16LVNpZ25hdHVyZT04YzJlZmQ1N2I5MWFhYTQ2OTg0OTMwZjFiN2Q3NjUwMDdkMGQ5ZWZhMzg3OGM0Yjk5NjlkYjdkZTEzNTg1YzJm&#39;, &#39;Content-Type&#39;: &#39;application/json&#39;} timeout = None query_params = None r = c.api_client.rest_client.pool_manager.request( &quot;GET&quot;, url, preload_content=True, body={}, headers=headers, timeout=None . from kubernetes import client, config . dir(config.kube_config.Configuration) . from kubernetes import client, config # Configs can be set in Configuration class directly or using helper # utility. If no argument provided, the config will be loaded from # default location. config.load_kube_config() print(&quot;Supported APIs (* is preferred version):&quot;) print(&quot;%-40s %s&quot; % (&quot;core&quot;, &quot;,&quot;.join(client.CoreApi().get_api_versions().versions))) for api in client.ApisApi().get_api_versions().groups: versions = [] for v in api.versions: name = &quot;&quot; if v.version == api.preferred_version.version and len( api.versions) &gt; 1: name += &quot;*&quot; name += v.version versions.append(name) print(&quot;%-40s %s&quot; % (api.name, &quot;,&quot;.join(versions))) . headers = {&#39;Accept&#39;: &#39;application/json&#39;, &#39;User-Agent&#39;: &#39;OpenAPI-Generator/12.0.0-snapshot/python&#39;, &#39;authorization&#39;: &#39;Bearer k8s-aws-v1.aHR0cHM6Ly9zdHMudXMtZWFzdC0xLmFtYXpvbmF3cy5jb20vP0FjdGlvbj1HZXRDYWxsZXJJZGVudGl0eSZWZXJzaW9uPTIwMTEtMDYtMTUmWC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BU0lBM1JHTlg2V1BEWkhaRFhOQiUyRjIwMjAwOTAzJTJGdXMtZWFzdC0xJTJGc3RzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyMDA5MDNUMTUyMTU5WiZYLUFtei1FeHBpcmVzPTYwJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCUzQngtazhzLWF3cy1pZCZYLUFtei1TZWN1cml0eS1Ub2tlbj1Gd29HWlhJdllYZHpFTCUyRiUyRiUyRiUyRiUyRiUyRiUyRiUyRiUyRiUyRiUyRndFYURPTWRiNzM1NFBCMmlmRjVraUxuQWY4Q3dUaUY4NWQwUkV6ZyUyQk4lMkZodm90TmVJd0pBSFRsNDRVSlIzd2UlMkZEaGNHWmw5QTFOSTBOR01tM2E1YSUyQldjRURjbWVVWldSYlElMkYyNkJhcDJnNk9oNHZLMmVuajQ1YlB6d2ZBT2N2SGpPVGRvdnhZdFVLQ0U2RGZPJTJGM29YU3NxJTJCZG1tY3I0d0NFR09tajB1dTFIWnNCRSUyRmclMkZkJTJGRmg1eUk1SjUzJTJCdFUybHpyVE1uSERUdlFmNTY4VlZtWlhuZVcxN2YxbVc4UWYlMkZsdlhWVTNhJTJCdGpSbUsyUzJjdk5oVWJEclBmckclMkZmU3kxeUZ2eHQxY2wwcmZiaHJ3ZzU0RHdLNGZpSTEyRTRpb0puMGhuc3hMU2FsaWYlMkJVVFJQRFFXJTJCWVZEQWFQUEV2JTJGTHpLM1pMUU1neXlpRDJjUDZCVEl5UmI2bTNYVDVLMEJZSkVSQjZzZXR3T2s5UDBMYVBrc09LOGcxc0Jrbm1MTjJRSjVxYmo4Y2tkTjVUJTJGM0Q5eUVFMWNvJTNEJlgtQW16LVNpZ25hdHVyZT04YzJlZmQ1N2I5MWFhYTQ2OTg0OTMwZjFiN2Q3NjUwMDdkMGQ5ZWZhMzg3OGM0Yjk5NjlkYjdkZTEzNTg1YzJm&#39;, &#39;Content-Type&#39;: &#39;application/json&#39;} _preload_content = True timeout = None query_params = None url = &#39;https://2AC6C9C829888AF237C2E11472EFC08E.yl4.us-east-1.eks.amazonaws.com/api/&#39; . import urllib3.PoolManager help(urllib3.PoolManager) . config . dir(config) . dir(config.kube_config) .",
            "url": "http://drafts.nicktorba.com/kubernetes/python/2020/09/13/Building_PyKubeCtl.html",
            "relUrl": "/kubernetes/python/2020/09/13/Building_PyKubeCtl.html",
            "date": " • Sep 13, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Deploy First Microservice",
            "content": "Pre-reqs . Build a Seldon-core Microservice | Launch a local kubernetes cluster or any other kubernetes cluster readily available | . | . Goal . Deploy our docker image from Build a Seldon-core Microservice onto kubernetes! | . Steps . Define SeldonDeployment yaml file | kubectl apply SeldonDeployment to the kubernetes cluster. | Define SeldonDeployment yaml file . First, I show a completed seldon deployment configuration file. Under this file I walk through some of the important details to take take note of. In this example, we are deploying a custom python component. Seldon-core also provides pre-packaged model servers, which allow you to get models up faster, but the concepts don&#39;t transfer as well to more complex inference graphs with other components. . %%writefile iris_classifier/sklearn_iris_deployment.yaml #hide_output apiVersion: machinelearning.seldon.io/v1alpha2 kind: SeldonDeployment metadata: name: seldon-deployment-example spec: name: sklearn-iris-deployment predictors: - componentSpecs: - spec: containers: - image: seldonio/sklearn-iris:0.1 imagePullPolicy: IfNotPresent name: sklearn-iris-classifier graph: children: [] endpoint: type: REST name: sklearn-iris-classifier type: MODEL name: sklearn-iris-predictor replicas: 1 . Some important notes about the deployment config: . apiVersion: this sends out request to the appropriate endpoint of the kubernets api, which was installed by helm earlier in this tutorial learn more about this in our kubernetes posts | . | kind: tells Kubernetes what kind of resource to create. Because we installed seldon-core on our cluster, it recognizes SeldonDeployment as a custom resource | . | metadata: add labels, like name, to the deployment | spec: predictors: this is a list of predictors to deploy. It is a list because you have the option to create multiple inference graphs in the same spec. This is useful for things like Canary deployment, where you only want a new graph to recieve a small percentage of traffic componentSpecs: add information about the containers that need to be pulled to create our graph. In our case, we only need a single containe to serve our model. If we were creating a more complex inference graph (maybe with a transformer, router, and another model, then we would need to include the docker containers that house them in this section) | graph: this is where you define the flow of components. This is easy in our case, there is only one component so we define one endpoint with no children. If there were more compnoents, we would fill out the children componenets in the children attriubte of the head of the graph. Seldon graphs are built implicitly through the use of the children attribute of each node in the graph. | . | . | . There is one last step to deploy our graph, we must push our docker container to a registry! I am running a local registry with my kind cluster, thanks to the script given here. You can also push to DockerHub as well. . !docker push localhost:5000/iris_ex:latest . With our docker image in a registry, it is available to our cluster, so we can deploy! . !kubectl apply -f iris_classifier/sklearn_iris_deployment.yaml from time import sleep sleep(5) # give the clsuter some to get the deployment running before executing the rollout . You can check the status of your deployment. . !kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=seldon-deployment-example -o jsonpath=&#39;{.items[0].metadata.name}&#39;) . Once the deployment is ready, you will need to port-forward the pod to your localhost in order check the request. That can be done wiht kubectl port-forward command . kubectl port-forward $(kubectl get pods -l seldon-app=seldon-deployment-example-sklearn-iris-predictor -o jsonpath=&#39;{.items[0].metadata.name}&#39;) 9000:9000 . You must run this command in a separate window because it will need to run while we curl the endpoint. . import numpy as np import grpc from seldon_core.proto import prediction_pb2 from seldon_core.proto import prediction_pb2_grpc ### Test REST endpoint res = !curl -s http://localhost:9000/predict -H &quot;Content-Type: application/json&quot; -d &#39;{&quot;data&quot;:{&quot;ndarray&quot;:[[5.964,4.006,2.081,1.031]]}}&#39; print(res) . ## Cleanup !kubectl delete -f sklearn_iris_deployment.yaml . Conclusion . In this quick example, we scratched the surface of seldon-core by deploying a simple model endpoint on kubernetes. If you are hungry for more, chech out more of the posts in the Seldon Super Series. There, you can find notebooks similar to this that deploy more complex inference graphs, or dive into the underlying kubernetes concepts that seldon runs on top of! . ### Next Up * other seldon components * seldon graph construction * multi-component inference graph * operators and custom resources .",
            "url": "http://drafts.nicktorba.com/kubernetes/docker/2020/08/27/deploy-first-microservice.html",
            "relUrl": "/kubernetes/docker/2020/08/27/deploy-first-microservice.html",
            "date": " • Aug 27, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Build a Seldon-core Microservice",
            "content": "Reqs . docker To complete this tutorial, you must have docker installed and be able to run containers from the command line. | Run docker help at the command line. If this outputs the docker help menu, you are ready to follow along! | . | Goal . Prepare a docker image with seldon-core for deployment on kubernetes | . Steps . Define a seldon python component | Build docker image | Run a container to test code | Define Python Component . I&#39;m taking this example code directly from seldon-core irisClassifier example. This code is used to train the model that will be served in the seldon-core microservice. . #hide_output !mkdir iris_classifier . #collapse_show #hide_output import joblib from sklearn.pipeline import Pipeline from sklearn.linear_model import LogisticRegression from sklearn import datasets OUTPUT_FILE = &quot;iris_classifier/IrisClassifier.sav&quot; print(&quot;Loading iris data set...&quot;) iris = datasets.load_iris() X, y = iris.data, iris.target print(&quot;Dataset loaded!&quot;) clf = LogisticRegression(solver=&quot;liblinear&quot;, multi_class=&quot;ovr&quot;) p = Pipeline([(&quot;clf&quot;, clf)]) print(&quot;Training model...&quot;) p.fit(X, y) print(&quot;Model trained!&quot;) print(f&quot;Saving model in {OUTPUT_FILE}&quot;) joblib.dump(p, OUTPUT_FILE) print(&quot;Model saved!&quot;) . . Loading iris data set... Dataset loaded! Training model... Model trained! Saving model in iris_classifier/IrisClassifier.sav Model saved! . Next, we define the seldon python component that will be used to serve the model. Seldon has a few components. In this example, we only use the Model component. Seldon components hold the logic that will be implanted into the serving endpoint that seldon creates. The model component must have a predict function, which is called when the future endpoint is hit. The reason seldon is so useful is because this is the only python code we need to write to serve this model. Seldon provides the rest of the logic, which puts this component into a web server, to serve the model. . An important note about this section is that you&#39;lll see the file is named IrisClassifier.py, which is camelcased. This is important, and you should not change this. The file name and the python component class name must match. . %%writefile iris_classifier/IrisClassifier.py #collapse_show #hide_output import joblib class IrisClassifier(object): def __init__(self): self.model = joblib.load(&#39;IrisClassifier.sav&#39;) def predict(self,X,features_names): return self.model.predict_proba(X) . . Overwriting iris_classifier/IrisClassifier.py . Build Docker Image . After defining a python component, there are two ways to create the docker image necessary for deployment. . define a Dockerfile which launches the seldon microservice | use s2i to build the image directly from source code. | . I prefer manually defining a Dockerfile because it provides more control over the process. However, s2i is a great tool that works just as well. . Write requirements.txt . We must write a requirements.txt library with all requirements for the docker image listed. . %%writefile iris_classifier/requirements.txt #hide_output sklearn seldon-core . Define Dockerfile . The Dockerfile follows the example provided here. We start from the python:3.7-slim base image, copy the code from the current directory, which includes the python component we defined earlier, install requirements, then expose port 5000 for the microservice to run. Next, we define seldon specific variables. . MODEL_NAME must match the python file name (which also much match the python component class name). | API_TYPE can be either REST or GRPC. | SERVICE_TYPE is the type of seldon component. MODEL for this example. (explore the other seldon components here | PERSISTENCE: 0 or 1. Defaults to 0. If it is set to 1, the component class will be periodically persisted to reis. This s unnecessary for our case because the component class will not change. this would be more pertinent for components like routers, which can have updating states for long running jobs. | . | . %%writefile iris_classifier/Dockerfile #collapse_show #hide_output FROM python:3.7-slim COPY . /app WORKDIR /app RUN pip install -r requirements.txt EXPOSE 5000 # Define environment variable ENV MODEL_NAME IrisClassifier ENV API_TYPE REST ENV SERVICE_TYPE MODEL ENV PERSISTENCE 0 # seldon-core-microservice is a command line tool installed with the seldon-core python libray. You can use this locally as well! CMD exec seldon-core-microservice $MODEL_NAME $API_TYPE --service-type $SERVICE_TYPE --persistence $PERSISTENCE . . Overwriting iris_classifier/Dockerfile . To test this example, let&#39;s build and run the docker image! . Docker Build . Pass the iris_classifier dir where the image guts live, then pass a -t to tag the image with a name referring to your preferred docker image repository (I&#39;m running on locally). . #hide_output !docker build iris_classifier/ -t localhost:5000/iris_ex:latest . Test Image . Test the newly created docker image by running a container and hitting the endpoint! . #hide_output !docker run --name &quot;iris_predictor&quot; -d --rm -p 5001:5000 localhost:5000/iris_ex:latest . You could also remove the -d argument from the above command and run this command in a separate window to see the log output while sending requests to the endpoint. Test the endpoint with the curl below! . import numpy as np import grpc from seldon_core.proto import prediction_pb2 from seldon_core.proto import prediction_pb2_grpc ### Test Rest Endpoint !curl -s http://localhost:5001/predict -H &quot;Content-Type: application/json&quot; -d &#39;{&quot;data&quot;:{&quot;ndarray&quot;:[[5.964,4.006,2.081,1.031]]}}&#39; ### Test GRPC Endpoint # data = np.array([[5.964,4.006,2.081,1.031]]) # datadef = prediction_pb2.DefaultData( # tensor=prediction_pb2.Tensor(shape=data.shape, values=data.flatten()) # ) # request = prediction_pb2.SeldonMessage(data=datadef) # with grpc.insecure_channel(&quot;localhost:5001&quot;) as channel: # stub = prediction_pb2_grpc.ModelStub(channel) # response = stub.Predict(request=request) # print(response) . {&#34;data&#34;:{&#34;names&#34;:[],&#34;ndarray&#34;:[0.9481017681926894]},&#34;meta&#34;:{}} . If you see successful output, you have your first seldon-core microservice up and running, congrats! Use the next command to stop the running docker container: . !docker container rm iris_predictor --force . If you are like me, you are a bit surprised at just how easy it was to create this. That is the power of seldon. . You may also ask yourself, &quot;if I have a working docker image, what do I need kubernetes for?&quot; This is a great question. For simple use cases, this docker image itself is all you need, and you could run it as a standalone service. If the load is small and you can run it without any load balancing functionalities, you are good to go. However, kubernetes is a container orchestration engine. That means it is built to handle complex containerized applications and will make your life much easier if you need to handle more complex operations for applications that need to serve on a large scale. . You may also wonder, I thought this series was to learn about kubernets? Don&#39;t worry, it is. This post is meant to serve. as the jumping off point for much more detail about kubernetes. Kubernetes is useless unless you have container based microservices to run on it. This is also a straightforward and a rewarding way to start. . At this stage you are prepared to move onto any of these posts: . Deploy First Microservice This post is for those excited to deploy your new docker image on kubernetes! | . | Build Various Seldon-core microservices This post is for those more interested in learning about the other seldon components beside models | . | . STOP HERE . Once the docker image is created, I will create a new post that is specific to launching on kubernetes | Getting a working docker image is half the battle, and this can be a big success for users this is also a great jumping off point to instead say, want to make a more complex inference graph before kubernetes? or want to go learn about other python components before moving on to kubernetes? | . | 1) building docker, 2) launch on kubernetes in the light of mouldarity, I am better off keeping these steps separate from each other so users can focus on the docker and seldon stuff if they like | this has the other advantage that if users struggle with getting a local k8s cluster up, they can still leaving the tutorials feelings they have gained a good understanding of seldon because they have their nice docker images they built | . | . First, let&#39;s take down the running docker container: .",
            "url": "http://drafts.nicktorba.com/seldon-core/docker/2020/07/30/first-seldon-core-microservice.html",
            "relUrl": "/seldon-core/docker/2020/07/30/first-seldon-core-microservice.html",
            "date": " • Jul 30, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Exploring Kubernetes API",
            "content": "Kubernets API . The Kubernetes api is how all communication is passed to and within a kubernetes cluster. Any commands sent to kubernetes cluster with kubectl are hitting endpoints in the kubernetes cluster, which allow the cluster to make the appropriate changes. . Luckly for us, kubernetes makes it easy to explore the api through the use of kubectl proxy. In this post we will look through the different paths of the api to see how different functionalites are exposed . !kind create cluster --name explore . Creating cluster &#34;explore&#34; ... ✓ Ensuring node image (kindest/node:v1.17.0) 🖼 ✓ Preparing nodes 📦 7l ✓ Writing configuration 📜7l ✓ Starting control-plane 🕹️7l ✓ Installing CNI 🔌7l ✓ Installing StorageClass 💾7l Set kubectl context to &#34;kind-explore&#34; You can now use your cluster with: kubectl cluster-info --context kind-explore Have a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community 🙂 . !kubectx kind-explore . Switched to context &#34;kind-explore&#34;. . !kubectl get pods . No resources found in default namespace. . With a new cluster up and running, go to a terminal, and end the command kubectl proxy --port=8000 (if port 8000 is taken, use a different number). You will want to run this command in a terminal because the server itself will need be running while we continue to execute commands from this notebook or your webrowser. . Kubectl proxy is a built-in kubernetes command that exposes the kubernetes api to the user. With a kubectl proxy server running locally, we can visit the different api paths to see information about what api endpoints are available. . To start exploring the kubernetes api, either go to http://127.0.0.1:8000/apis in your browser, or use a curl in this notebook: . !curl http://127.0.0.1:8000/apis . { &#34;kind&#34;: &#34;APIGroupList&#34;, &#34;apiVersion&#34;: &#34;v1&#34;, &#34;groups&#34;: [ { &#34;name&#34;: &#34;apiregistration.k8s.io&#34;, &#34;versions&#34;: [ { &#34;groupVersion&#34;: &#34;apiregistration.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; }, { &#34;groupVersion&#34;: &#34;apiregistration.k8s.io/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } ], &#34;preferredVersion&#34;: { &#34;groupVersion&#34;: &#34;apiregistration.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; } }, { &#34;name&#34;: &#34;extensions&#34;, &#34;versions&#34;: [ { &#34;groupVersion&#34;: &#34;extensions/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } ], &#34;preferredVersion&#34;: { &#34;groupVersion&#34;: &#34;extensions/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } }, { &#34;name&#34;: &#34;apps&#34;, &#34;versions&#34;: [ { &#34;groupVersion&#34;: &#34;apps/v1&#34;, &#34;version&#34;: &#34;v1&#34; } ], &#34;preferredVersion&#34;: { &#34;groupVersion&#34;: &#34;apps/v1&#34;, &#34;version&#34;: &#34;v1&#34; } }, { &#34;name&#34;: &#34;events.k8s.io&#34;, &#34;versions&#34;: [ { &#34;groupVersion&#34;: &#34;events.k8s.io/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } ], &#34;preferredVersion&#34;: { &#34;groupVersion&#34;: &#34;events.k8s.io/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } }, { &#34;name&#34;: &#34;authentication.k8s.io&#34;, &#34;versions&#34;: [ { &#34;groupVersion&#34;: &#34;authentication.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; }, { &#34;groupVersion&#34;: &#34;authentication.k8s.io/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } ], &#34;preferredVersion&#34;: { &#34;groupVersion&#34;: &#34;authentication.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; } }, { &#34;name&#34;: &#34;authorization.k8s.io&#34;, &#34;versions&#34;: [ { &#34;groupVersion&#34;: &#34;authorization.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; }, { &#34;groupVersion&#34;: &#34;authorization.k8s.io/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } ], &#34;preferredVersion&#34;: { &#34;groupVersion&#34;: &#34;authorization.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; } }, { &#34;name&#34;: &#34;autoscaling&#34;, &#34;versions&#34;: [ { &#34;groupVersion&#34;: &#34;autoscaling/v1&#34;, &#34;version&#34;: &#34;v1&#34; }, { &#34;groupVersion&#34;: &#34;autoscaling/v2beta1&#34;, &#34;version&#34;: &#34;v2beta1&#34; }, { &#34;groupVersion&#34;: &#34;autoscaling/v2beta2&#34;, &#34;version&#34;: &#34;v2beta2&#34; } ], &#34;preferredVersion&#34;: { &#34;groupVersion&#34;: &#34;autoscaling/v1&#34;, &#34;version&#34;: &#34;v1&#34; } }, { &#34;name&#34;: &#34;batch&#34;, &#34;versions&#34;: [ { &#34;groupVersion&#34;: &#34;batch/v1&#34;, &#34;version&#34;: &#34;v1&#34; }, { &#34;groupVersion&#34;: &#34;batch/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } ], &#34;preferredVersion&#34;: { &#34;groupVersion&#34;: &#34;batch/v1&#34;, &#34;version&#34;: &#34;v1&#34; } }, { &#34;name&#34;: &#34;certificates.k8s.io&#34;, &#34;versions&#34;: [ { &#34;groupVersion&#34;: &#34;certificates.k8s.io/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } ], &#34;preferredVersion&#34;: { &#34;groupVersion&#34;: &#34;certificates.k8s.io/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } }, { &#34;name&#34;: &#34;networking.k8s.io&#34;, &#34;versions&#34;: [ { &#34;groupVersion&#34;: &#34;networking.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; }, { &#34;groupVersion&#34;: &#34;networking.k8s.io/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } ], &#34;preferredVersion&#34;: { &#34;groupVersion&#34;: &#34;networking.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; } }, { &#34;name&#34;: &#34;policy&#34;, &#34;versions&#34;: [ { &#34;groupVersion&#34;: &#34;policy/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } ], &#34;preferredVersion&#34;: { &#34;groupVersion&#34;: &#34;policy/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } }, { &#34;name&#34;: &#34;rbac.authorization.k8s.io&#34;, &#34;versions&#34;: [ { &#34;groupVersion&#34;: &#34;rbac.authorization.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; }, { &#34;groupVersion&#34;: &#34;rbac.authorization.k8s.io/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } ], &#34;preferredVersion&#34;: { &#34;groupVersion&#34;: &#34;rbac.authorization.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; } }, { &#34;name&#34;: &#34;storage.k8s.io&#34;, &#34;versions&#34;: [ { &#34;groupVersion&#34;: &#34;storage.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; }, { &#34;groupVersion&#34;: &#34;storage.k8s.io/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } ], &#34;preferredVersion&#34;: { &#34;groupVersion&#34;: &#34;storage.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; } }, { &#34;name&#34;: &#34;admissionregistration.k8s.io&#34;, &#34;versions&#34;: [ { &#34;groupVersion&#34;: &#34;admissionregistration.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; }, { &#34;groupVersion&#34;: &#34;admissionregistration.k8s.io/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } ], &#34;preferredVersion&#34;: { &#34;groupVersion&#34;: &#34;admissionregistration.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; } }, { &#34;name&#34;: &#34;apiextensions.k8s.io&#34;, &#34;versions&#34;: [ { &#34;groupVersion&#34;: &#34;apiextensions.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; }, { &#34;groupVersion&#34;: &#34;apiextensions.k8s.io/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } ], &#34;preferredVersion&#34;: { &#34;groupVersion&#34;: &#34;apiextensions.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; } }, { &#34;name&#34;: &#34;scheduling.k8s.io&#34;, &#34;versions&#34;: [ { &#34;groupVersion&#34;: &#34;scheduling.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; }, { &#34;groupVersion&#34;: &#34;scheduling.k8s.io/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } ], &#34;preferredVersion&#34;: { &#34;groupVersion&#34;: &#34;scheduling.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; } }, { &#34;name&#34;: &#34;coordination.k8s.io&#34;, &#34;versions&#34;: [ { &#34;groupVersion&#34;: &#34;coordination.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; }, { &#34;groupVersion&#34;: &#34;coordination.k8s.io/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } ], &#34;preferredVersion&#34;: { &#34;groupVersion&#34;: &#34;coordination.k8s.io/v1&#34;, &#34;version&#34;: &#34;v1&#34; } }, { &#34;name&#34;: &#34;node.k8s.io&#34;, &#34;versions&#34;: [ { &#34;groupVersion&#34;: &#34;node.k8s.io/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } ], &#34;preferredVersion&#34;: { &#34;groupVersion&#34;: &#34;node.k8s.io/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } }, { &#34;name&#34;: &#34;discovery.k8s.io&#34;, &#34;versions&#34;: [ { &#34;groupVersion&#34;: &#34;discovery.k8s.io/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } ], &#34;preferredVersion&#34;: { &#34;groupVersion&#34;: &#34;discovery.k8s.io/v1beta1&#34;, &#34;version&#34;: &#34;v1beta1&#34; } } ] } . You&#39;ll see a big json reponse of kind APIGroupList. This response shows a list of kubernets APIGroups, which are a mechanism kubernetes uses to make it easier for users to extend the kubernetes api (We will see how the seldon custom resource definition extends this api by the end of this post!) . !kubectl create namespace tester . namespace/tester created . !kubens tester . Context &#34;kind-explore&#34; modified. Active namespace is &#34;tester&#34;. . !curl http://127.0.0.1:8000/api/v1 . { &#34;kind&#34;: &#34;APIResourceList&#34;, &#34;groupVersion&#34;: &#34;v1&#34;, &#34;resources&#34;: [ { &#34;name&#34;: &#34;bindings&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;Binding&#34;, &#34;verbs&#34;: [ &#34;create&#34; ] }, { &#34;name&#34;: &#34;componentstatuses&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: false, &#34;kind&#34;: &#34;ComponentStatus&#34;, &#34;verbs&#34;: [ &#34;get&#34;, &#34;list&#34; ], &#34;shortNames&#34;: [ &#34;cs&#34; ] }, { &#34;name&#34;: &#34;configmaps&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;ConfigMap&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;delete&#34;, &#34;deletecollection&#34;, &#34;get&#34;, &#34;list&#34;, &#34;patch&#34;, &#34;update&#34;, &#34;watch&#34; ], &#34;shortNames&#34;: [ &#34;cm&#34; ], &#34;storageVersionHash&#34;: &#34;qFsyl6wFWjQ=&#34; }, { &#34;name&#34;: &#34;endpoints&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;Endpoints&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;delete&#34;, &#34;deletecollection&#34;, &#34;get&#34;, &#34;list&#34;, &#34;patch&#34;, &#34;update&#34;, &#34;watch&#34; ], &#34;shortNames&#34;: [ &#34;ep&#34; ], &#34;storageVersionHash&#34;: &#34;fWeeMqaN/OA=&#34; }, { &#34;name&#34;: &#34;events&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;Event&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;delete&#34;, &#34;deletecollection&#34;, &#34;get&#34;, &#34;list&#34;, &#34;patch&#34;, &#34;update&#34;, &#34;watch&#34; ], &#34;shortNames&#34;: [ &#34;ev&#34; ], &#34;storageVersionHash&#34;: &#34;r2yiGXH7wu8=&#34; }, { &#34;name&#34;: &#34;limitranges&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;LimitRange&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;delete&#34;, &#34;deletecollection&#34;, &#34;get&#34;, &#34;list&#34;, &#34;patch&#34;, &#34;update&#34;, &#34;watch&#34; ], &#34;shortNames&#34;: [ &#34;limits&#34; ], &#34;storageVersionHash&#34;: &#34;EBKMFVe6cwo=&#34; }, { &#34;name&#34;: &#34;namespaces&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: false, &#34;kind&#34;: &#34;Namespace&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;delete&#34;, &#34;get&#34;, &#34;list&#34;, &#34;patch&#34;, &#34;update&#34;, &#34;watch&#34; ], &#34;shortNames&#34;: [ &#34;ns&#34; ], &#34;storageVersionHash&#34;: &#34;Q3oi5N2YM8M=&#34; }, { &#34;name&#34;: &#34;namespaces/finalize&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: false, &#34;kind&#34;: &#34;Namespace&#34;, &#34;verbs&#34;: [ &#34;update&#34; ] }, { &#34;name&#34;: &#34;namespaces/status&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: false, &#34;kind&#34;: &#34;Namespace&#34;, &#34;verbs&#34;: [ &#34;get&#34;, &#34;patch&#34;, &#34;update&#34; ] }, { &#34;name&#34;: &#34;nodes&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: false, &#34;kind&#34;: &#34;Node&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;delete&#34;, &#34;deletecollection&#34;, &#34;get&#34;, &#34;list&#34;, &#34;patch&#34;, &#34;update&#34;, &#34;watch&#34; ], &#34;shortNames&#34;: [ &#34;no&#34; ], &#34;storageVersionHash&#34;: &#34;XwShjMxG9Fs=&#34; }, { &#34;name&#34;: &#34;nodes/proxy&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: false, &#34;kind&#34;: &#34;NodeProxyOptions&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;delete&#34;, &#34;get&#34;, &#34;patch&#34;, &#34;update&#34; ] }, { &#34;name&#34;: &#34;nodes/status&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: false, &#34;kind&#34;: &#34;Node&#34;, &#34;verbs&#34;: [ &#34;get&#34;, &#34;patch&#34;, &#34;update&#34; ] }, { &#34;name&#34;: &#34;persistentvolumeclaims&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;PersistentVolumeClaim&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;delete&#34;, &#34;deletecollection&#34;, &#34;get&#34;, &#34;list&#34;, &#34;patch&#34;, &#34;update&#34;, &#34;watch&#34; ], &#34;shortNames&#34;: [ &#34;pvc&#34; ], &#34;storageVersionHash&#34;: &#34;QWTyNDq0dC4=&#34; }, { &#34;name&#34;: &#34;persistentvolumeclaims/status&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;PersistentVolumeClaim&#34;, &#34;verbs&#34;: [ &#34;get&#34;, &#34;patch&#34;, &#34;update&#34; ] }, { &#34;name&#34;: &#34;persistentvolumes&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: false, &#34;kind&#34;: &#34;PersistentVolume&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;delete&#34;, &#34;deletecollection&#34;, &#34;get&#34;, &#34;list&#34;, &#34;patch&#34;, &#34;update&#34;, &#34;watch&#34; ], &#34;shortNames&#34;: [ &#34;pv&#34; ], &#34;storageVersionHash&#34;: &#34;HN/zwEC+JgM=&#34; }, { &#34;name&#34;: &#34;persistentvolumes/status&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: false, &#34;kind&#34;: &#34;PersistentVolume&#34;, &#34;verbs&#34;: [ &#34;get&#34;, &#34;patch&#34;, &#34;update&#34; ] }, { &#34;name&#34;: &#34;pods&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;Pod&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;delete&#34;, &#34;deletecollection&#34;, &#34;get&#34;, &#34;list&#34;, &#34;patch&#34;, &#34;update&#34;, &#34;watch&#34; ], &#34;shortNames&#34;: [ &#34;po&#34; ], &#34;categories&#34;: [ &#34;all&#34; ], &#34;storageVersionHash&#34;: &#34;xPOwRZ+Yhw8=&#34; }, { &#34;name&#34;: &#34;pods/attach&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;PodAttachOptions&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;get&#34; ] }, { &#34;name&#34;: &#34;pods/binding&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;Binding&#34;, &#34;verbs&#34;: [ &#34;create&#34; ] }, { &#34;name&#34;: &#34;pods/eviction&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;group&#34;: &#34;policy&#34;, &#34;version&#34;: &#34;v1beta1&#34;, &#34;kind&#34;: &#34;Eviction&#34;, &#34;verbs&#34;: [ &#34;create&#34; ] }, { &#34;name&#34;: &#34;pods/exec&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;PodExecOptions&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;get&#34; ] }, { &#34;name&#34;: &#34;pods/log&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;Pod&#34;, &#34;verbs&#34;: [ &#34;get&#34; ] }, { &#34;name&#34;: &#34;pods/portforward&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;PodPortForwardOptions&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;get&#34; ] }, { &#34;name&#34;: &#34;pods/proxy&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;PodProxyOptions&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;delete&#34;, &#34;get&#34;, &#34;patch&#34;, &#34;update&#34; ] }, { &#34;name&#34;: &#34;pods/status&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;Pod&#34;, &#34;verbs&#34;: [ &#34;get&#34;, &#34;patch&#34;, &#34;update&#34; ] }, { &#34;name&#34;: &#34;podtemplates&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;PodTemplate&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;delete&#34;, &#34;deletecollection&#34;, &#34;get&#34;, &#34;list&#34;, &#34;patch&#34;, &#34;update&#34;, &#34;watch&#34; ], &#34;storageVersionHash&#34;: &#34;LIXB2x4IFpk=&#34; }, { &#34;name&#34;: &#34;replicationcontrollers&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;ReplicationController&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;delete&#34;, &#34;deletecollection&#34;, &#34;get&#34;, &#34;list&#34;, &#34;patch&#34;, &#34;update&#34;, &#34;watch&#34; ], &#34;shortNames&#34;: [ &#34;rc&#34; ], &#34;categories&#34;: [ &#34;all&#34; ], &#34;storageVersionHash&#34;: &#34;Jond2If31h0=&#34; }, { &#34;name&#34;: &#34;replicationcontrollers/scale&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;group&#34;: &#34;autoscaling&#34;, &#34;version&#34;: &#34;v1&#34;, &#34;kind&#34;: &#34;Scale&#34;, &#34;verbs&#34;: [ &#34;get&#34;, &#34;patch&#34;, &#34;update&#34; ] }, { &#34;name&#34;: &#34;replicationcontrollers/status&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;ReplicationController&#34;, &#34;verbs&#34;: [ &#34;get&#34;, &#34;patch&#34;, &#34;update&#34; ] }, { &#34;name&#34;: &#34;resourcequotas&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;ResourceQuota&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;delete&#34;, &#34;deletecollection&#34;, &#34;get&#34;, &#34;list&#34;, &#34;patch&#34;, &#34;update&#34;, &#34;watch&#34; ], &#34;shortNames&#34;: [ &#34;quota&#34; ], &#34;storageVersionHash&#34;: &#34;8uhSgffRX6w=&#34; }, { &#34;name&#34;: &#34;resourcequotas/status&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;ResourceQuota&#34;, &#34;verbs&#34;: [ &#34;get&#34;, &#34;patch&#34;, &#34;update&#34; ] }, { &#34;name&#34;: &#34;secrets&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;Secret&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;delete&#34;, &#34;deletecollection&#34;, &#34;get&#34;, &#34;list&#34;, &#34;patch&#34;, &#34;update&#34;, &#34;watch&#34; ], &#34;storageVersionHash&#34;: &#34;S6u1pOWzb84=&#34; }, { &#34;name&#34;: &#34;serviceaccounts&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;ServiceAccount&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;delete&#34;, &#34;deletecollection&#34;, &#34;get&#34;, &#34;list&#34;, &#34;patch&#34;, &#34;update&#34;, &#34;watch&#34; ], &#34;shortNames&#34;: [ &#34;sa&#34; ], &#34;storageVersionHash&#34;: &#34;pbx9ZvyFpBE=&#34; }, { &#34;name&#34;: &#34;services&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;Service&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;delete&#34;, &#34;get&#34;, &#34;list&#34;, &#34;patch&#34;, &#34;update&#34;, &#34;watch&#34; ], &#34;shortNames&#34;: [ &#34;svc&#34; ], &#34;categories&#34;: [ &#34;all&#34; ], &#34;storageVersionHash&#34;: &#34;0/CO1lhkEBI=&#34; }, { &#34;name&#34;: &#34;services/proxy&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;ServiceProxyOptions&#34;, &#34;verbs&#34;: [ &#34;create&#34;, &#34;delete&#34;, &#34;get&#34;, &#34;patch&#34;, &#34;update&#34; ] }, { &#34;name&#34;: &#34;services/status&#34;, &#34;singularName&#34;: &#34;&#34;, &#34;namespaced&#34;: true, &#34;kind&#34;: &#34;Service&#34;, &#34;verbs&#34;: [ &#34;get&#34;, &#34;patch&#34;, &#34;update&#34; ] } ] } .",
            "url": "http://drafts.nicktorba.com/kubernetes/api/2020/07/27/exploring-kubernetes-api.html",
            "relUrl": "/kubernetes/api/2020/07/27/exploring-kubernetes-api.html",
            "date": " • Jul 27, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Depth over Breadth",
            "content": "Depth over breadth was introduced to me while listening to The Art of Learning by Josh Waitzkin. The main idea is that you can gain a much better understanding of the bigger picture (any object or field of study) by digging deep on a seemingly small part. For example, as a software engineer, depth over breadth is dedicating your time to a single programming language instead of trying to learn 3 at once. A deep understanding of a single language improves your general programming ability more than a shallow understanding of many. Not to mention, learning new languages after a deep understanding of one opens the door to many important, nuanced connections. . Digging into the small part is what Josh calls the micro. “Depth over breadth” is understanding the macro (programming in general) from the micro (a single programming language). . A great example Josh uses in the book is from The Art of Motorcycle Maintenance. The main character, Phadreus, is a professor at a college in Bozeman, Montana. He teaches literature and writing. At one point, a notably hard working student is stumped with writer’s block. The assignment is to write 500 words about Bozeman, a small town in rural Montana. Despite her determination, she just can’t get any words on the page. After many attempts to help, Phradreus frustratedly tells her “Narrow it down to the front of one building on the main street of Bozeman. The Opera House. Start with the upper left-hand brick.” The next day, the girl turns in a 5000 word essay. Starting with a single brick, she receives endless inspiration. Starting with something so small (the micro) gave her an entirely new view of the whole town (the macro). . This idea takes our original software analogy even further. Forget focusing on an entire language. Focus on a single library. Tear it apart. Use the debugger and step through all levels of the code. Look at how the authors abstracted their ideas. Analyze the data structures. Look for the use of language specific features. Contribute to it. . Deep understanding of a single library does much more than just help you understand that library. As you use others, you begin to see important connections, or striking differences. Those connections help you pick up new libraries much faster. You also begin to build a much deeper understanding of the language itself. . With a strategy like this, you build a deeper understanding of the macro (a programming language, or even programming itself) by narrowing in on the micro (a specific library of a single language). .",
            "url": "http://drafts.nicktorba.com/markdown/learning/learning%20strategies/growth/2020/07/24/depth-over-breadth.html",
            "relUrl": "/markdown/learning/learning%20strategies/growth/2020/07/24/depth-over-breadth.html",
            "date": " • Jul 24, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "Custom Resources and Operators",
            "content": "Intro . In this post we will walk through the basics behind the seldon custom resource definition. At a high level, kubernetes only job is to maintain the desired state of the cluster. All interactions are changes to the desired state. The magic of kubernetes is that once you tell it the new state, it creates and maintains that state for you. The seldon-core projects serves inferences graphs on kubernetes with a custom resource and operator. These provide automation of complex systems, while allowing us to easily configure the desired state of our deployments without doing a lot of manual work. . Launch Cluster . To get started, let&#39;s get a cluster up and running. If you followed part 1 of this series, you can do so with kind. Below, I create a cluster, create a namespace called seldon-intro, then use kubens to make seldon-into my default namespace (so I don&#39;t have to include it in every command). . !kind create cluster !kubectl create namespace seldon-intro !kubens seldon-intro . Creating cluster &#34;kind&#34; ... ✓ Ensuring node image (kindest/node:v1.17.0) 🖼7l ✓ Preparing nodes 📦 7l ✓ Writing configuration 📜7l ✓ Starting control-plane 🕹️7l ✓ Installing CNI 🔌7l ✓ Installing StorageClass 💾7l Set kubectl context to &#34;kind-kind&#34; You can now use your cluster with: kubectl cluster-info --context kind-kind Have a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community 🙂 . KubeAPI, Custom Resources, and Operators . The KubeAPI is the medium through which all communication is handled in a kubernetes cluster. It is a rest server. When you send commands to a kubernetes cluster, you are hitting a specific api endpoint with commands for the server to execute. Kubernetes comes with some built-in objects you should be familiar with. Deployments, services, pods, etc. These objects are useful in and of themselves, but we often need to use many of them at once, which can get cumbersome. For those familiar with seldon, you know that you can create very complex inference graphs with many components. Instead of deploying and connecting all seldon services manually, we are able to build a single json/yaml configuration that deploys the entire graph. This is possible because of operators and custom resources. Operators and custom resources have an intimate relationship, and must be used in tandem. Earlier, I introduce the KubeAPI. We know that is how all internal and external communication is handled in the cluster. With operators, we extend the KubeAPI. In other words, operators allow us to add more endpoints to the KubeApi to carry out custom commands in our cluster. Which is where custom resources come in. They define the custom instructions for our new endpoint to execute. Let&#39;s see an operator and custom resource in action. . Install Seldon-core . I suggest using helm to install seldon-core. If you haven&#39;t used helm before, use this page to find install instructions. (If you&#39;re on a mac, just use brew install helm). For those familiar with python, helm is like the pip for kubernetes. It works by using helm charts. A chart is a group of files that describe a higher level application using built-in kubernetes resources. For example, you could use a helm chart to deploy a full stack web application. We are going to use helm to install seldon-core and seldon-core-operator. These helm charts are what will allow us to deploy seldon inference graphs. You can learn more about helm charts here. . Once helm is installed, use it to install seldon-core and seldon-core-operator with the following command: . !helm install seldon-core seldon-core-operator --repo https://storage.googleapis.com/seldon-charts --set usageMetrics.enabled=true --set ambassador.enabled=true --namespace seldon-intro #unnecessary after using `kubens seldon-intro`, but keeping here to make sure the install is explicit . NAME: seldon-core LAST DEPLOYED: Mon Jul 27 08:32:08 2020 NAMESPACE: seldon-intro STATUS: deployed REVISION: 1 TEST SUITE: None . After a successful install of seldon-core and seldon-core-operator, run the following command: . !kubectl get deployments . NAME READY UP-TO-DATE AVAILABLE AGE seldon-controller-manager 1/1 1 1 6s . We see we now have a deployment, seldon-controller-manager, running in our seldon-intro namespace. . !!kubectl describe svc seldon-webhook-service . [&#39;Name: seldon-webhook-service&#39;, &#39;Namespace: seldon-intro&#39;, &#39;Labels: app=seldon&#39;, &#39; app.kubernetes.io/instance=seldon-core&#39;, &#39; app.kubernetes.io/managed-by=Helm&#39;, &#39; app.kubernetes.io/name=seldon-core-operator&#39;, &#39; app.kubernetes.io/version=1.2.1&#39;, &#39;Annotations: meta.helm.sh/release-name: seldon-core&#39;, &#39; meta.helm.sh/release-namespace: seldon-intro&#39;, &#39;Selector: app.kubernetes.io/instance=seldon1,app.kubernetes.io/name=seldon,app.kubernetes.io/version=v0.5,app=seldon,control-plane=seldon-controller-manager&#39;, &#39;Type: ClusterIP&#39;, &#39;IP: 10.96.113.42&#39;, &#39;Port: &lt;unset&gt; 443/TCP&#39;, &#39;TargetPort: 443/TCP&#39;, &#39;Endpoints: 10.244.0.5:443&#39;, &#39;Session Affinity: None&#39;, &#39;Events: &lt;none&gt;&#39;] . The docker image name used to create the seldon-controller-manager pod and deployment is called docker.io/seldonio/seldon-core-operator:1.2.1. That is because the seldon-controller-manager is the seldon-core-operator. . Be sure to match the last line with the namespace you created in the previous command. We will talk more about what the other lines mean later in the series. After installing, run . !kubectl get pods -o wide . and you&#39;ll see you have a pod running with seldon-controller-manager in the name (followed by a random string, we will talk about why that is soon). Next, run . !kubectl get deployments . Seldon-controller-manager is a kubernetes operator. As described here, kubernetes operators are extensions of the kubernetes api that allow users to easily package and deploy complex applications on kubernetes. The seldon-core-operator adds a lot of functionality to the kubernetes cluster and allows us to interact with seldon deployments as if they were a built-in kubernetes object. Along with this, we also installed the seldon-core custom resource definition. Kubernetes custom resources are extensions of the native kuberetes api. As you will see soon, we will now be able to deploy and interact with a new structure, the sdep, in the same fashion we deploy and monitor kubernetes deployments, servives, and other built-in resources. . All interactions with a kubernetes cluster is the user specifying a new desired state, and the kubernetes cluster using it&#39;s resources to change into that desired state. When, a custom resource is created, an operator is needed as well to tell kubernetes how to handle updates to the desired state of the custom resource. The seldon-core operator is what allows users to make edits to currently running seldon deployments without downtime. . Operators allows kubernetes to run stateful applications. A popular usecase for operators is databases. . To get a better idea at how helm charts add to your kubernetes cluster, check out the Exploring the Kubernetes API post digs into the basic internals of how your cluster actually receives commands. . In this post, they write . If you had to sum up Kubernetes in a word, the best choice might not be “orchestration” but “automation.” That’s what it’s all about:Kubernetes enables the automation of the infrastructure (and corresponding operational burden of managing that infrastructure) necessary for running containerized applications – a must when running these apps at scale in production environments. This is very evident with the Seldon deployment CRD and operator. As we move along and start to create our own seldon deployments, you will see the power of this automation. With a single file, a seldon deployment will launch multiple services, deployments, pods, and allow for continuous updates of all those components through the Kubernetes api. Seldon has leveraged the power of the automation offered by kubernetes to create inferences graphs of many components. . Another great quote from that article: . “Operators are simplifying the process highly complex distributed database management by defining the installation, scale, updates, and management lifecycle of a stateful clustered application,” says Yossi Jana, DevOps team leader at AllCloud. From another vantage point, consider life without Operators. “Without Operators, many applications need intervention to deploy, scale, reconfigure, upgrade, or recover from faults,” Thompson says. “If your app – or apps that you depend on, such as your database management system – [requires] DevOps engineers hovering over a keyboard in these critical moments, hoping they get the steps correctly, you’re almost certain to have greater downtime and more stress in your team.” . From kubernetes-operator-sdk tutorial, operators are used to define custom resources. They extend the kubernetes api to tell the cluster how to handle those resources. Operators themselves run in pods. This is why you see the seldon-controller-manager deployment and pod running after we install seldon-core with helm. . As described in the kubernetes docs here, operators follow the controller pattern, which means they are responsible for keep the desired state of the custom resource they are responsible for. The seldon-core-operator is responsbile for the Seldon Deployment custom resource. That means, when we create or edit a seldon deployment, the seldon-core-operator is responsible for adjusting the kubernetes deployment to the desired state to meet the new edits applied by the user. . In every article you read about kubernetes operators, you&#39;ll find some sentiment to the fact that is confusing the first time around. In fact, pretty much everything you learn about kubernetes will be confusing the first time around. Don&#39;t let that discourage you. That is why we are using seldon to help our understanding. Instead of reading description after description of what a custom resource and operator are, let&#39;s actually use them to begin to understand the power they provide. . Let&#39;s launch our first seldon deployment onto the cluster to see what the consequences of creating a seldon deployment custom resource are. . %%bash kubectl apply -f - &lt;&lt; END apiVersion: machinelearning.seldon.io/v1alpha2 kind: SeldonDeployment metadata: name: iris-model spec: name: sklearn-iris-deployment predictors: - componentSpecs: - spec: containers: - image: seldonio/sklearn-iris:0.1 imagePullPolicy: IfNotPresent name: sklearn-iris-classifier graph: children: [] endpoint: type: REST name: sklearn-iris-classifier type: MODEL name: predictor replicas: 1 END . !kubectl get pods .",
            "url": "http://drafts.nicktorba.com/kubernetes/docker/2020/07/20/dive-into-operators-and-custom-resources.html",
            "relUrl": "/kubernetes/docker/2020/07/20/dive-into-operators-and-custom-resources.html",
            "date": " • Jul 20, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "Cluster Interaction Basics",
            "content": "Intro . This post walks through some kubernetes basics and launches your first deployment and service on your cluster. .",
            "url": "http://drafts.nicktorba.com/kubernetes/docker/2020/07/18/cluster-interaction-basics.html",
            "relUrl": "/kubernetes/docker/2020/07/18/cluster-interaction-basics.html",
            "date": " • Jul 18, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "Seldon Super Series",
            "content": "Intro . I work on a team building an ML platform to allow researchers to deploy, monitor, and iterate on production machine learning models. The platform leverages seldon-core, an open source platform to deploy scalable machine learning models on kubernetes. Kubernetes is an intimidating subject. From the control-plane, to pods, to volumes, to everything else, there is always more you didn’t even know you didn’t know. My journey to getting familiar with kubernetes was learning through seldon-core. I had never used kubernetes before, but to leverage seldon, it is necessary. Over the past few months I’ve become comfortable developing, debugging, and deploying projects on a kubernetes cluster. Seldon-core is a great project to build kubernetes knowledge around. It leverages some advanced kubernetes concepts under the hood, while remaining easy to use and powerful. Not to mention, it is much easier to build motivation around a subject when you are actually building, instead of just reading the documentation. . Goals . I am not a kubernetes expert, but I have become comfortable enough to be highly productive working with kubernetes. This comfort level was developed through muscle memory using common kubectl commands, learning the basics of kubernetes built-in objects vs custom resources, finding errors, and more. With that in mind, here are my goals: . Give readers a clear path to the “highly productive with kubernetes” level. | Have readers match my comfort level in only one week. | To do this, the Seldon Super Series lays out a path providing the best resources I found along with new examples I wrote based on my learning experience. . Who’s it for? . This series is useful for programmers (preferably comfortable in python) looking to build a deeper understanding of kubernetes. Seldon-core is just a great vehicle for this learning. If you are also interested in leveraging seldon, all the better! You can be a complete kubernetes beginner, or come with some familiarity. If you are already familiar with kubernetes, feel free to jump to posts further into the series that get into more complex material! All of the examples throughout this tutorial are written in python. Most of the code examples are straightforward, with the focus on kubernetes and seldon, so even if you have a different preferred language, you should be able to following along just as well. . How to get started . If you are completely new to kubernetes, there is no better place to start than the kubernetes interactive tutorial. I suggest following this tutorial all the way through before getting started on anything else. It requires no install, no setup, and introduces fundamentals used when working with any app deployed on a cluster. | If you don’t have access to a kubernetes cluster, follow Launch a local kubernetes cluster to get a kubernetes cluster running on your local machine with kind. I suggest using kind because it is free and you can freely experiment with the comfort that it takes less than a minute to destroy and reboot your cluster at any time. If that doesn’t work for you, there are many good resources available to get a cluster running on AWS or Google Cloud. You will have to pay for these, but you will only need a small cluster that will be fairly cheap | . | Once you have a cluster to hack on, get started with First Seldon-core Microservice. Even if you have previous seldon experience, I suggest starting, here, because many other posts will use this as a baseline to build on (don’t worry if you don’t start here, though, any post that does require some setup will make that clear). | . Launch a local kubernetes cluster Get a local kubernetes cluster up and running so you can experiment locally! Important for those of us who don’t have easy access to a remote cluster. | . | First Seldon-core Microservice Deploy a model endpoint on kubernetes! | . | Multi-component Seldon Deployment Use multiple seldon-core components to deploy and inference graph! | . | Explore the Kubernetes API Use kubectl proxy to understand how to communicate with a kubernetes cluster! | . | Seldon-core Custom Resource and Operator. Create your first seldon deployment and read about what makes the seldon deployment custom resource so useful. Take a closer look at how seldon-core and seldon-core-operator extend the kubernetes api and make it easy to deploy seldon inference graphs! | . | Debugging Seldon Deployments. Take a look at where to find your logs and diagnosis some common issues. | Seldon-core analytics and load testing with Locust | Multi-pod Seldon Deployments. Deploy individual components of your inference graph in their own pods to define custom deployment specs! | . | Horizontal Pod Autoscaling Seldon Deployments Autoscaling your deployments! | . | CD with Argocd * Try out Argocd for continuous deployment! | Why Seldon-core? . Seldon-core is an open source projects built by the London based startup Seldon. With seldon-core, you can use python (and java) to easily deploy ML models built in any framework at scale. However, they offer tools for more than just model serving. With seldon-core, you construct an inference graph. The inference graph is built with these components: . Model | Transformer | Combiner | Router These additional components add the ability to create much more than just a single model. You can set up custom A/B tests, multi-armed bandits, scalable ensemble systems, and much more. In short, seldon-core inference graphs are powerful! | .",
            "url": "http://drafts.nicktorba.com/markdown/seldon/kubernetes/python/2020/07/17/seldon-super-series.html",
            "relUrl": "/markdown/seldon/kubernetes/python/2020/07/17/seldon-super-series.html",
            "date": " • Jul 17, 2020"
        }
        
    
  
    
        ,"post12": {
            "title": "Local Kubernetes on KIND",
            "content": "Intro . Welcome to the first post of the Seldon Super Series! This post is for those who don&#39;t yet have access to a kubernetes cluster. We&#39;ll walkthrough how to use Kind to launch a cluster on you local machine! If you already have access to a kubernetes cluster, and also have kubectl installed, then move onto part 2! Otherwise, follow along here before you move on! . Reqs . None! This is the first post in the series! | . Goals . Launch a local kubernets cluster using kind, and install seldon on the cluster to allow you to follow along with the rest of the posts in this series | . Install kubectl . If this is the first time you&#39;ve used kubernetes, you will need to install kubectl, the command line tool for interacting with kubernetes. This can be downloaded here. On mac you can use brew install kubectl. Check your install by running: . !kubectl version --client --short . Client Version: v1.18.5 . You should see output similar to this. It shouldn&#39;t be a problem if you&#39;re version is a bit different than this. . Install Kind . If you&#39;re on mac, it&#39;s as simple as brew install kind. If not, check out this page . Create your First Cluster . Todo: ADD LOCAL REGISTRY. They need this for the following examples (or access to DockerHub) . !kind create cluster . Creating cluster &#34;kind&#34; ... ✓ Ensuring node image (kindest/node:v1.17.0) 🖼 ✓ Preparing nodes 📦 7l ✓ Writing configuration 📜7l ✓ Starting control-plane 🕹️7l ✓ Installing CNI 🔌7l ✓ Installing StorageClass 💾7l Set kubectl context to &#34;kind-kind&#34; You can now use your cluster with: kubectl cluster-info --context kind-kind Thanks for using kind! 😊 . It&#39;s as simple as that. If it is your first time running kind, it will automatically download the appropiate docker image (something like kindest/node:1.17.0), which may take a few minutes. After that command is finished, check if your cluster is running: . !kubectl cluster-info . Kubernetes master is running at https://127.0.0.1:32771 KubeDNS is running at https://127.0.0.1:32771/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy To further debug and diagnose cluster problems, use &#39;kubectl cluster-info dump&#39;. . If you see output like above, displaying info about your Kubernetes master and KubeDNS, then you have successfully launched a local kubernetes cluster! . Install Seldon-core . Because we will need seldon-core for all of the following posts, we will install it here. Anytime you need to re-launch a kind cluster to follow along the other posts, you will be able to run this notebook to get it back up and running. . To install seldon-core on the cluster, use helm. To install helm itself, find directions here, or use brew install helm on mac. . Once helm is installed, use it to install seldon-core and seldon-core-operator with the following command: . !helm install seldon-core seldon-core-operator --repo https://storage.googleapis.com/seldon-charts --set usageMetrics.enabled=true --set ambassador.enabled=true --namespace seldon-intro . !kubectl get pods print(&quot;--&quot;) !kubectl get deployments . You should see a pod and deployment with seldon-controller-manager in the name. This pod and deployment house the seldon-core operator, extends the kubernetes api. For now, just confirming that pod is running is all we need. . Bonus: Install kubectx and kubens . As you follow through the next posts, I will be using the kubectx and kubens command line tools. If you are on mac, you can install them with brew: brew install kubectx. This will download and install both kubectx and kubens. If you&#39;re not on mac, find install instructions here. These allow you to easily switch between kubernetes contexts and namespaces. You can perform all the same actions with kubectl, but kubectx and kubens make some common commands much quicker. .",
            "url": "http://drafts.nicktorba.com/kubernetes/docker/2020/07/17/local-kubernetes-with-seldon.html",
            "relUrl": "/kubernetes/docker/2020/07/17/local-kubernetes-with-seldon.html",
            "date": " • Jul 17, 2020"
        }
        
    
  
    
        ,"post13": {
            "title": "Good At Math Bad At Writing",
            "content": "Good at Math, Bad at Writing . The biggest failure of my education was the acceptance of the “good at math, bad at writing” label. It comes as no surprise that I ended up working as a software engineer, but it took until now to see how much time I wasted hating writing, when in fact, the underlying principles are strikingly similar. . Looking at the end product, the similarities are hard to see. Books and programs are much different, but the process to generate them is quite similar. For both, the ultimate goal is to give the user/reader (“user” for software and “reader” for writing - they serve the same purpose) a particular experience by providing information in a well thought out structure. This goal is achieved using a set of tools and conventions. Software leverages programming languages with different designs (object oriented vs functional, for example) and frameworks (web application vs data application). Writing leverages spoken language with accepted structures such as short-stories, books, long-form, and poems. In both, deciding the general structure and design (picking a programming language vs picking a writing structure) is integral to creating the end experience you wish to generate. . Software engineers specialize in particular niches similar to authors specializing in particular structures. I build data applications with python to improve the experience of data scientists while poets use poems to create an experience for their readers. In the end, the best software engineers and writers are those who most effectively organize and present necessary information to their audience. . It is sometimes easy to miss when this is done well, but never hard to miss when done poorly. Everyone knows the absolute frustration of using software that is particularly difficult to understand or flat out doesn’t do what its supposed to. While bad writing leaves you lost, or worse, leaves you in apparent understanding, only later finding you completely missed the point the author wanted to get across (something I’ve had happen in my writing many a time). Both of these are results of bad information organization. At some point the creators mis executed along their path to creating the experience they planned on. . Most disciplines share the same underlying principles. These hidden connections is what makes me so sad about the all too common “Good at math, bad at writing” label given to so many students at such a young age. It is harmful to plant this idea in a young mind, blocking them from the hidden connections they then don’t bother to look for. I’ve come to realize how important and enjoyable writing is in my everyday life. Not only do you need to write more than ever to communicate with work colleagues via slack and email, but nothing can help boost memory more than writing well thought out notes about new topics and ideas. . I’m angry at any teacher who allowed this idea to propagate or ever did a shitty job teaching an English class. English teachers have such a great opportunity to showcase how important writing is to every aspect of life and they squandered it. . This realization has been very important to me. I will forever despise the “good at math, bad at writing” because of the limitations it tricks people into thinking they have. .",
            "url": "http://drafts.nicktorba.com/2020/05/07/Good-at-Math-Bad-At-Writing.html",
            "relUrl": "/2020/05/07/Good-at-Math-Bad-At-Writing.html",
            "date": " • May 7, 2020"
        }
        
    
  
    
        ,"post14": {
            "title": "Exploring Metaflow",
            "content": "About . metaflow is a python package open sourced by netflix to help data scientists easily scale their project workflows. Metaflow is mainly interacted with through decorators. In this post, we will get behind the scenes of how these decorators actually work. . The code . To start, let&#39;s take a look at the first example in the documentation. This is a simple flow. . from metaflow import FlowSpec, step class LinearFlow(FlowSpec): @step def start(self): self.my_var = &#39;hello world&#39; self.next(self.a) @step def a(self): print(&#39;the data artifact is: %s&#39; % self.my_var) self.next(self.end) @step def end(self): print(&#39;the data artifact is still: %s&#39; % self.my_var) LinearFlow() . We see that the LinearFlow python class inherits from metaflow&#39;s FlowSpec class, and each of the functions are decorated with @step. As seen (here)[https://docs.metaflow.org/metaflow/basics], this basic flow follows metaflow&#39;s guidelines. However, what is actually happening? How does it turn our functions into pipeline steps? Let&#39;s start by taking a look at the Flowspec class. . (Flowspec)[https://github.com/Netflix/metaflow/blob/master/metaflow/flowspec.py] definition and constructor. Full code can be found at the link. . class FlowSpec(object): &quot;&quot;&quot; Main class from which all Flows should inherit. Attributes - script_name index input &quot;&quot;&quot; # Attributes that are not saved in the datastore when checkpointing. # Name starting with &#39;__&#39;, methods, functions and Parameters do not need # to be listed. _EPHEMERAL = {&#39;_EPHEMERAL&#39;, &#39;_datastore&#39;, &#39;_cached_input&#39;, &#39;_graph&#39;, &#39;_flow_decorators&#39;, &#39;_steps&#39;, &#39;index&#39;, &#39;input&#39;} _flow_decorators = {} def __init__(self, use_cli=True): &quot;&quot;&quot; Construct a FlowSpec Parameters - use_cli : bool, optional, default: True Set to True if the flow is invoked from __main__ or the command line &quot;&quot;&quot; self.name = self.__class__.__name__ self._datastore = None self._transition = None self._cached_input = {} self._graph = FlowGraph(self.__class__) self._steps = [getattr(self, node.name) for node in self._graph] if use_cli: # we import cli here to make sure custom parameters in # args.py get fully evaluated before cli.py is imported. from . import cli cli.main(self) .",
            "url": "http://drafts.nicktorba.com/jupyter/2020/03/08/metaflow-exploration.html",
            "relUrl": "/jupyter/2020/03/08/metaflow-exploration.html",
            "date": " • Mar 8, 2020"
        }
        
    
  
    
        ,"post15": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . Front Matter is a markdown cell at the beginning of your notebook that allows you to inject metadata into your notebook. For example: . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks just like you can with markdown. . For example, here is a footnote 1. . . This is the footnote.&#8617; . |",
            "url": "http://drafts.nicktorba.com/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post16": {
            "title": "Test Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 . Footnotes . This is the footnote. &#8617; . |",
            "url": "http://drafts.nicktorba.com/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "About Me . Trying to get better at writing because it seems like a good thing to get good at. .",
          "url": "http://drafts.nicktorba.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}